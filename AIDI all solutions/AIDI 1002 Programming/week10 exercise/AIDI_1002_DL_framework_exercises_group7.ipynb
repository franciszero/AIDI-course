{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arzrt6PaD3Iw"
   },
   "source": [
    "Note: If you are having difficulty installing the tensorflow, keras and pytorch libraries, use google colab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NrrTtpODN_s"
   },
   "source": [
    "# Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHGdSo4tDRwR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm9JA4-iCrBR"
   },
   "source": [
    "# Keras implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MABKXAOoCgrN",
    "outputId": "c31b5aec-2ef5-477b-f46c-5c733b69f26d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n",
      "65536/57026 [==================================] - 0s 0us/step\n",
      "train_data.shape (404, 13)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "# 404 training samples and 102 test samples, \n",
    "# each with 13 numerical feature\n",
    "print(\"train_data.shape\", train_data.shape)\n",
    "\n",
    "# normalize the data\n",
    "mean = train_data.mean(axis=0)\n",
    "\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpgmTpFAC9z9"
   },
   "outputs": [],
   "source": [
    "# few samples are available, use a very small network \n",
    "# with two hidden layers, each with 64 units. \n",
    "# In general, the less training data you have, \n",
    "# the worse overfitting will be, and using a small network \n",
    "# is one way to mitigate overfitting.\n",
    "\n",
    "from keras import Sequential, layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "            input_shape = (train_data.shape[1],)))\n",
    "    \n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dense(32,activation = 'relu'))\n",
    "\n",
    "    # network ends with a single unit and no activation. \n",
    "    # This is a typical setup for scalar regression \n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHl3bmm_DFQI",
    "outputId": "ffb4c4e6-68d4-4a71-a0b4-f0228d204d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 18.5859 - mae: 2.7118\n",
      "test_mae_score 2.712\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "\n",
    "print(\"test_mae_score\", np.round(test_mae_score,3)) \n",
    "\n",
    "# mae value around 2.54 -> \\$2,540 \n",
    "# (house price range \\$10,000-\\$50,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZSATQ5mDvO0"
   },
   "source": [
    "# PyTorch implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRkvHkjaDKJW"
   },
   "outputs": [],
   "source": [
    "#Define the model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AskZ_L0oEndJ"
   },
   "source": [
    "## data preprocessing\n",
    "- data house pricing data is downloaded from another source in this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvH-x-bVELov",
    "outputId": "320cafad-70a7-4050-cb17-252e3c49c38f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#From sklearn tutorial.\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "# print( \"Type of boston dataset:\", type(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84Tm3BzuEPH-"
   },
   "outputs": [],
   "source": [
    "#A bunch is you remember is a dictionary based dataset.  Dictionaries are addressed by keys. \n",
    "#Let's look at the keys. \n",
    "# print(boston.keys())\n",
    "\n",
    "#DESCR sounds like it could be useful. Let's print the description.\n",
    "# print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ovBEXOF3ETy0",
    "outputId": "a27ef881-b8f8-43db-e965-97fb89015c9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-41e6c6e9-ef6f-4a1f-8a89-17b81f24b558\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41e6c6e9-ef6f-4a1f-8a89-17b81f24b558')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-41e6c6e9-ef6f-4a1f-8a89-17b81f24b558 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-41e6c6e9-ef6f-4a1f-8a89-17b81f24b558');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        0     1     2    3      4   ...   8      9     10      11    12\n",
       "0  0.00632  18.0  2.31  0.0  0.538  ...  1.0  296.0  15.3  396.90  4.98\n",
       "1  0.02731   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  396.90  9.14\n",
       "2  0.02729   0.0  7.07  0.0  0.469  ...  2.0  242.0  17.8  392.83  4.03\n",
       "3  0.03237   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  394.63  2.94\n",
       "4  0.06905   0.0  2.18  0.0  0.458  ...  3.0  222.0  18.7  396.90  5.33\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's change the data to a Panda's Dataframe\n",
    "boston_df = pd.DataFrame(boston['data'] )\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "q5Xa9jZMEcUG",
    "outputId": "05426487-31a3-4ac7-8224-7e428ba24b75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-05590a82-7865-4d2b-aca4-a04d4073faae\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05590a82-7865-4d2b-aca4-a04d4073faae')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-05590a82-7865-4d2b-aca4-a04d4073faae button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-05590a82-7865-4d2b-aca4-a04d4073faae');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
       "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
       "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
       "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
       "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
       "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now add the column names.\n",
    "boston_df.columns = boston['feature_names']\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YHsssdXiEhxi",
    "outputId": "0967ea16-68cf-4d56-fa95-3336dfc0fa6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-54e65c3d-372f-4e10-9852-202f93558d2a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54e65c3d-372f-4e10-9852-202f93558d2a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-54e65c3d-372f-4e10-9852-202f93558d2a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-54e65c3d-372f-4e10-9852-202f93558d2a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE\n",
       "0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0\n",
       "1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6\n",
       "2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7\n",
       "3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4\n",
       "4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the target as PRICE. \n",
    "boston_df['PRICE']= boston['target']\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1y5d_OngEz9m",
    "outputId": "0a21a05d-4d26-48ea-caf3-a3d43a2e9ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13) (152, 13) (354,) (152,)\n"
     ]
    }
   ],
   "source": [
    "#This will throw and error at import if haven't upgraded. \n",
    "# from sklearn.cross_validation  import train_test_split  \n",
    "from sklearn.model_selection  import train_test_split\n",
    "#y is the dependent variable.\n",
    "y = boston_df['PRICE']\n",
    "#As we know, iloc is used to slice the array by index number. Here this is the matrix of \n",
    "#independent variables.\n",
    "X = boston_df.iloc[:,0:13]\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgOtJqvWG9QD"
   },
   "outputs": [],
   "source": [
    "#Change to numpy array. \n",
    "X_train=X_train.values\n",
    "y_train=y_train.values\n",
    "X_test=X_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBFpKb1IE431"
   },
   "outputs": [],
   "source": [
    "#Define training hyperprameters.\n",
    "batch_size = 50\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "size_hidden= 100\n",
    "\n",
    "#Calculate some other hyperparameters based on data.  \n",
    "batch_no = len(X_train) // batch_size  #batches\n",
    "cols = X_train.shape[1] #Number of columns in input matrix\n",
    "n_output=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k48ssV64E6nr",
    "outputId": "d720672f-042c-466a-97be-d7d8416de90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the model on : cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(\"Executing the model on :\",device)\n",
    "\n",
    "#Create the model object\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(cols, size_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(size_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "model_pytorch = Net(cols, size_hidden, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-i1TSO5qE9vA",
    "outputId": "4c0c783e-253f-4657-9371-4c0bd0082c93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "#Adam is a specific flavor of gradient decent which is typically better\n",
    "optimizer = torch.optim.Adam(model_pytorch.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJnYt74EFILU",
    "outputId": "2ff44181-8c4f-4192-f3f4-bfbc14806192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss:  3090.8970336914062\n",
      "Epoch 40 loss:  3142.290237426758\n",
      "Epoch 60 loss:  2969.9196166992188\n",
      "Epoch 80 loss:  2844.443878173828\n",
      "Epoch 100 loss:  4001.4786376953125\n",
      "Epoch 120 loss:  2559.8975219726562\n",
      "Epoch 140 loss:  2969.085174560547\n",
      "Epoch 160 loss:  3262.7972106933594\n",
      "Epoch 180 loss:  2391.389617919922\n",
      "Epoch 200 loss:  2381.66455078125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "running_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Shuffle just mixes up the dataset between epochs\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "    # Mini batch learning\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "        labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_pytorch(inputs)\n",
    "        #print(\"outputs\",outputs)\n",
    "        #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "        \n",
    "        loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # print progress every 20th epoch\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print('Epoch {}'.format(epoch+1), \"loss: \",running_loss)\n",
    "    running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDhX1MbSFKdm"
   },
   "outputs": [],
   "source": [
    "#This is a little bit tricky to get the resulting prediction.  \n",
    "def calculate_r2_mae(x,y=[]):\n",
    "    \"\"\"\n",
    "    This function will return the r2 if passed x and y or return predictions if just passed x. \n",
    "    \"\"\"\n",
    "\n",
    "    # Evaluate the model with the test set. \n",
    "    X = Variable(torch.FloatTensor(x))  \n",
    "    \n",
    "    result = model_pytorch(X) #This outputs the value for regression\n",
    "    result = result.data[:,0].numpy()\n",
    "  \n",
    "    if len(y) != 0:\n",
    "        r2 = r2_score(result, y)\n",
    "        mae = mean_absolute_error(result, y)\n",
    "        print(\"R-Squared: %.3f, MAE: %.2f\" %(r2, mae))\n",
    "        \n",
    "        #print('Accuracy {:.2f}'.format(num_right / len(y)), \"for a total of \", len(y), \"records\")\n",
    "        return pd.DataFrame(data= {'actual': y, 'predicted': result})\n",
    "    else:\n",
    "        print(\"returning predictions\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqbPHYaQH0IE",
    "outputId": "a79bf11c-eebb-403a-aee6-7584843bbd6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared: 0.905, MAE: 1.89\n",
      "R-Squared: 0.678, MAE: 2.74\n"
     ]
    }
   ],
   "source": [
    "result1 = calculate_r2_mae(X_train,y_train)\n",
    "result2 = calculate_r2_mae(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICOdL0Q-IV4T"
   },
   "source": [
    "# Exercises:\n",
    "- modify above NN model with different number of dense layers, hidden units, loss function, # of training epochs etc to identify a prediction model with better performance (i.e., lower MAE value and higher r2 value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWlYT49CH4pi",
    "outputId": "dfe3fbdc-8eca-46b9-c1a9-90d475aa042d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (404, 13)\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 17.4845 - mae: 3.0709\n",
      "test_mae_score 3.071\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.datasets import boston_housing\n",
    "from keras import Sequential, layers\n",
    "\n",
    "class Foo:\n",
    "    def __init__(self):\n",
    "        (self.train_data, self.train_targets), (self.test_data, self.test_targets) = boston_housing.load_data()\n",
    "        # 404 training samples and 102 test samples,\n",
    "        # each with 13 numerical feature\n",
    "        print(\"train_data.shape\", self.train_data.shape)\n",
    "\n",
    "        # normalize the data\n",
    "        mean = self.train_data.mean(axis=0)\n",
    "        self.train_data -= mean\n",
    "        std = self.train_data.std(axis=0)\n",
    "        self.train_data /= std\n",
    "        self.test_data -= mean\n",
    "        self.test_data /= std\n",
    "\n",
    "    # few samples are available, use a very small network\n",
    "    # with two hidden layers, each with 64 units.\n",
    "    # In general, the less training data you have,\n",
    "    # the worse overfitting will be, and using a small network\n",
    "    # is one way to mitigate overfitting.\n",
    "\n",
    "    def build_model(self, l1, a1, l2=128, a2='relu', l3=64, a3='relu', l4=32, a4='relu'):\n",
    "        model = Sequential()\n",
    "        model.add(layers.Dense(l1, activation=a1, input_shape=(self.train_data.shape[1],)))\n",
    "        model.add(layers.Dense(l2, activation=a2))\n",
    "        model.add(layers.Dense(l3, activation=a3))\n",
    "        model.add(layers.Dense(l4, activation=a4))\n",
    "\n",
    "        # network ends with a single unit and no activation.\n",
    "        # This is a typical setup for scalar regression\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def eval(self, l1=128, a1='relu', l2=128, a2='relu', l3=64, a3='relu', l4=32, a4='relu', epoc=80):\n",
    "        model = self.build_model(l1, a1, l2, a2, l3, a3, l4, a4)\n",
    "        model.fit(self.train_data, self.train_targets, epochs=epoc, batch_size=16, verbose=0)\n",
    "        test_mse_score, test_mae_score = model.evaluate(self.test_data, self.test_targets)\n",
    "        print(\"test_mae_score\", np.round(test_mae_score, 3))\n",
    "        # mae value around 2.54 -> \\$2,540 \n",
    "        # (house price range \\$10,000-\\$50,000)\n",
    "\n",
    "foo = Foo()\n",
    "foo.eval(l1=128, a1='relu', l2=128, a2='relu', l3=64, a3='relu', l4=32, a4='relu', epoc=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1669964371379,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "5Q7_hycWKEma",
    "outputId": "0011870d-df4b-4558-fd47-fc8b1b80f850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13) (152, 13) (354,) (152,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_features, l1=128, l2=128, l3=16, l4=16, l5=4, l6=4, output=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.h0 = torch.nn.Linear(input_features, l1)\n",
    "        self.h1 = torch.nn.Linear(l1, l2)\n",
    "        self.h2 = torch.nn.Linear(l2, l3)\n",
    "        self.h3 = torch.nn.Linear(l3, l4)\n",
    "        self.h4 = torch.nn.Linear(l4, l5)\n",
    "        self.h5 = torch.nn.Linear(l5, l6)\n",
    "        self.output_layer = torch.nn.Linear(l6, output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h0(x))\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.relu(self.h2(x))\n",
    "        x = F.relu(self.h3(x))\n",
    "        x = F.relu(self.h4(x))\n",
    "        x = F.relu(self.h5(x))\n",
    "        # x = F.rrelu(self.h0(x))\n",
    "        # x = F.rrelu(self.h1(x))\n",
    "        # x = F.rrelu(self.h2(x))\n",
    "        # x = F.rrelu(self.h3(x))\n",
    "        # x = F.rrelu(self.h4(x))\n",
    "        # x = F.rrelu(self.h5(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Foo:\n",
    "    def __init__(self):\n",
    "        boston = load_boston()\n",
    "        boston_df = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "        boston_df['PRICE'] = boston['target']\n",
    "        self.X = boston_df.iloc[:, 0:13]\n",
    "        self.y = boston_df['PRICE']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "            train_test_split(self.X, self.y, test_size=0.3, random_state=0)\n",
    "\n",
    "        print(self.X_train.shape, self.X_test.shape, self.y_train.shape, self.y_test.shape)\n",
    "\n",
    "        self.X_train = self.X_train.values\n",
    "        self.y_train = self.y_train.values\n",
    "        self.X_test = self.X_test.values\n",
    "        self.y_test = self.y_test.values\n",
    "        self.cols = self.X_train.shape[1]  # Number of columns in input matrix\n",
    "        self.model_pytorch = None\n",
    "\n",
    "    def eval(self, batch_size=50, num_epochs=200, learning_rate=0.01, criterion=torch.nn.HuberLoss(reduction='sum')):\n",
    "        batch_no = len(self.X_train) // batch_size  # batches\n",
    "\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # # Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "        # print(\"Executing the model on :\", device)\n",
    "\n",
    "        # self.model_pytorch = Net(self.cols, size_hidden, self.n_output)\n",
    "\n",
    "        # Adam is a specific flavor of gradient decent which is typically better\n",
    "        optimizer = torch.optim.Adam(self.model_pytorch.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Shuffle just mixes up the dataset between epochs\n",
    "            X_train, y_train = shuffle(self.X_train, self.y_train)\n",
    "\n",
    "            # Mini batch learning\n",
    "            for i in range(batch_no):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "                inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "                labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self.model_pytorch(inputs)\n",
    "                # print(\"outputs\",outputs)\n",
    "                # print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "\n",
    "                loss = criterion(outputs, torch.unsqueeze(labels, dim=1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # print progress every 20th epoch\n",
    "            if (epoch + 1) % 1000 == 0:\n",
    "                print('Epoch {}'.format(epoch + 1), \"loss: \", running_loss)\n",
    "            running_loss = 0.0\n",
    "        result1 = self.calculate_r2_mae(self.X_train, self.y_train)\n",
    "        result2 = self.calculate_r2_mae(self.X_test, self.y_test)\n",
    "        pass\n",
    "\n",
    "    def calculate_r2_mae(self, x, y=None):\n",
    "        \"\"\"\n",
    "        This function will return the r2 if passed x and y or return predictions if just passed x.\n",
    "        \"\"\"\n",
    "\n",
    "        # Evaluate the model with the test set.\n",
    "        if y is None:\n",
    "            y = []\n",
    "        X = Variable(torch.FloatTensor(x))\n",
    "\n",
    "        result = self.model_pytorch(X)  # This outputs the value for regression\n",
    "        result = result.data[:, 0].numpy()\n",
    "\n",
    "        if len(y) != 0:\n",
    "            r2 = r2_score(result, y)\n",
    "            mae = mean_absolute_error(result, y)\n",
    "            print(\"R-Squared: %.3f, MAE: %.2f\" % (r2, mae))\n",
    "\n",
    "            # print('Accuracy {:.2f}'.format(num_right / len(y)), \"for a total of \", len(y), \"records\")\n",
    "            return pd.DataFrame(data={'actual': y, 'predicted': result})\n",
    "        else:\n",
    "            print(\"returning predictions\")\n",
    "            return result\n",
    "\n",
    "\n",
    "foo = Foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgzZGynygl2r"
   },
   "source": [
    "##### Round One ：random tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40346,
     "status": "ok",
     "timestamp": 1669961884919,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "O9SleqCeKEma",
    "outputId": "2f523cc1-860b-42b7-acdd-360bb20c1753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  4.399343550205231\n",
      "Epoch 2000 loss:  1.8710781633853912\n",
      "Epoch 3000 loss:  2.811720758676529\n",
      "R-Squared: 0.984, MAE: 0.89\n",
      "R-Squared: 0.736, MAE: 3.19\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=256, l2=256, l3=16, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=80, num_epochs=3000, learning_rate=0.002, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24854,
     "status": "ok",
     "timestamp": 1669962038024,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "NcBZAHmwLtA_",
    "outputId": "ee1881fe-3cdd-47c2-e1b8-34555182a80b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  2.36799955368042\n",
      "Epoch 2000 loss:  1.702791452407837\n",
      "Epoch 3000 loss:  1.538000226020813\n",
      "Epoch 4000 loss:  1.2366721630096436\n",
      "Epoch 5000 loss:  1.1024945974349976\n",
      "Epoch 6000 loss:  1.203973412513733\n",
      "Epoch 7000 loss:  1.1298693418502808\n",
      "Epoch 8000 loss:  1.0961107015609741\n",
      "Epoch 9000 loss:  0.8285300731658936\n",
      "Epoch 10000 loss:  0.9039367437362671\n",
      "R-Squared: 0.936, MAE: 1.24\n",
      "R-Squared: 0.732, MAE: 2.74\n"
     ]
    }
   ],
   "source": [
    "# candidate\n",
    "foo.model_pytorch = Net(foo.cols, l1=32, l2=32, l3=16, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.001, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27898,
     "status": "ok",
     "timestamp": 1669961844588,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "1zXVLrrPTYGE",
    "outputId": "78e6d815-f396-4261-ec3b-8e3fdb5c15bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  28.672372817993164\n",
      "Epoch 2000 loss:  10.635968804359436\n",
      "Epoch 3000 loss:  5.3301162123680115\n",
      "R-Squared: 0.984, MAE: 0.85\n",
      "R-Squared: 0.670, MAE: 2.92\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=32, l2=32, l3=16, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=80, num_epochs=3000, learning_rate=0.002, criterion=torch.nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25464,
     "status": "ok",
     "timestamp": 1669961200448,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "t1_KYPryTYID",
    "outputId": "b774b479-ef5e-4294-c7a9-8ebe1ea52106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  8.045549631118774\n",
      "Epoch 2000 loss:  6.6873239278793335\n",
      "Epoch 3000 loss:  5.609277009963989\n",
      "R-Squared: 0.959, MAE: 1.20\n",
      "R-Squared: 0.686, MAE: 2.76\n"
     ]
    }
   ],
   "source": [
    "# candidate\n",
    "foo.model_pytorch = Net(foo.cols, l1=32, l2=32, l3=16, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=80, num_epochs=3000, learning_rate=0.002, criterion=torch.nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28926,
     "status": "ok",
     "timestamp": 1669961338391,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "bLDeLwo3KEmb",
    "outputId": "bda75a95-93d8-4387-c919-c93321830085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  6.032895803451538\n",
      "Epoch 2000 loss:  3.2592626214027405\n",
      "Epoch 3000 loss:  3.3008354902267456\n",
      "R-Squared: 0.952, MAE: 1.41\n",
      "R-Squared: 0.616, MAE: 2.95\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=32, l2=32, l3=16, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=80, num_epochs=3000, learning_rate=0.002, criterion=torch.nn.SmoothL1Loss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al1TtRDKgHjE"
   },
   "source": [
    "##### Round Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25968,
     "status": "ok",
     "timestamp": 1669962261263,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "1S_AxYHTc9Qj",
    "outputId": "3902eac5-c5fc-45d1-bc34-ee41f0ff42be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  3.0773916244506836\n",
      "Epoch 2000 loss:  1.939092755317688\n",
      "Epoch 3000 loss:  1.6914304494857788\n",
      "Epoch 4000 loss:  1.4642313718795776\n",
      "Epoch 5000 loss:  1.327182650566101\n",
      "Epoch 6000 loss:  1.3554364442825317\n",
      "Epoch 7000 loss:  1.2726833820343018\n",
      "Epoch 8000 loss:  1.2102246284484863\n",
      "Epoch 9000 loss:  1.153406023979187\n",
      "Epoch 10000 loss:  1.1837083101272583\n",
      "R-Squared: 0.907, MAE: 1.57\n",
      "R-Squared: 0.727, MAE: 2.81\n"
     ]
    }
   ],
   "source": [
    "# candidate\n",
    "foo.model_pytorch = Net(foo.cols, l1=40, l2=40, l3=20, l4=20, l5=5, l6=5, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29150,
     "status": "ok",
     "timestamp": 1669962399935,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "EmEkaBAmgwKX",
    "outputId": "2f29b2c3-b508-4d46-c7f1-d904e166b937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  11.214197635650635\n",
      "Epoch 2000 loss:  5.816370368003845\n",
      "R-Squared: 0.986, MAE: 0.73\n",
      "R-Squared: 0.702, MAE: 2.95\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=40, l2=40, l3=20, l4=20, l5=5, l6=5, output=1)\n",
    "foo.eval(batch_size=50, num_epochs=2000, learning_rate=0.0025, criterion=torch.nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28952,
     "status": "ok",
     "timestamp": 1669962290201,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "1GsdBsarc9Ov",
    "outputId": "f312bb00-f232-4e4f-ea8f-1eea0ff69ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  3.4325881004333496\n",
      "Epoch 2000 loss:  2.1185545921325684\n",
      "Epoch 3000 loss:  2.0576887130737305\n",
      "Epoch 4000 loss:  1.8347935676574707\n",
      "Epoch 5000 loss:  1.881821870803833\n",
      "Epoch 6000 loss:  1.7643747329711914\n",
      "Epoch 7000 loss:  1.715798258781433\n",
      "Epoch 8000 loss:  1.703466534614563\n",
      "Epoch 9000 loss:  1.5681095123291016\n",
      "Epoch 10000 loss:  1.8093498945236206\n",
      "R-Squared: 0.903, MAE: 1.60\n",
      "R-Squared: 0.701, MAE: 2.81\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=40, l2=40, l3=20, l4=20, l5=5, l6=5, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29197,
     "status": "ok",
     "timestamp": 1669962429117,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "Aq0KO7mGc9Sb",
    "outputId": "973b21c2-3d62-4e70-b824-3f14a59cab61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  10.722804069519043\n",
      "Epoch 2000 loss:  6.662779927253723\n",
      "R-Squared: 0.973, MAE: 1.01\n",
      "R-Squared: 0.676, MAE: 3.10\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=40, l2=40, l3=20, l4=20, l5=5, l6=5, output=1)\n",
    "foo.eval(batch_size=50, num_epochs=2000, learning_rate=0.0025, criterion=torch.nn.L1Loss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo6XEPP2hPNK"
   },
   "source": [
    "##### Round Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27756,
     "status": "ok",
     "timestamp": 1669962522699,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "UMdaoCyic9WH",
    "outputId": "986ec11e-cb5a-41aa-fcb9-f92acbee8fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  3.0664167404174805\n",
      "Epoch 2000 loss:  2.0225892066955566\n",
      "Epoch 3000 loss:  1.9428519010543823\n",
      "Epoch 4000 loss:  1.618125081062317\n",
      "Epoch 5000 loss:  1.5389405488967896\n",
      "Epoch 6000 loss:  1.4338011741638184\n",
      "Epoch 7000 loss:  1.4214279651641846\n",
      "Epoch 8000 loss:  1.2357490062713623\n",
      "Epoch 9000 loss:  1.3781185150146484\n",
      "Epoch 10000 loss:  1.203445553779602\n",
      "R-Squared: 0.892, MAE: 1.66\n",
      "R-Squared: 0.673, MAE: 2.75\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=80, l2=80, l3=10, l4=10, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33711,
     "status": "ok",
     "timestamp": 1669962576945,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "gz-emWeIc9YI",
    "outputId": "6f77fc40-ed85-4ab7-e60f-63d69ab08dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  3.0862627029418945\n",
      "Epoch 2000 loss:  1.7049287557601929\n",
      "Epoch 3000 loss:  1.6207152605056763\n",
      "Epoch 4000 loss:  1.2779059410095215\n",
      "Epoch 5000 loss:  1.2047287225723267\n",
      "Epoch 6000 loss:  1.1051175594329834\n",
      "Epoch 7000 loss:  1.0643014907836914\n",
      "Epoch 8000 loss:  1.0528960227966309\n",
      "Epoch 9000 loss:  0.9085228443145752\n",
      "Epoch 10000 loss:  0.8846355080604553\n",
      "R-Squared: 0.915, MAE: 1.35\n",
      "R-Squared: 0.719, MAE: 2.76\n"
     ]
    }
   ],
   "source": [
    "# candidate\n",
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=128, l3=10, l4=10, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52737,
     "status": "ok",
     "timestamp": 1669962648528,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "0UhTPz_dhuPK",
    "outputId": "ba73b9f1-bb2f-46ac-a3c0-027cc057b03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  2.173978090286255\n",
      "Epoch 2000 loss:  1.5364869832992554\n",
      "Epoch 3000 loss:  1.2361032962799072\n",
      "Epoch 4000 loss:  1.07366943359375\n",
      "Epoch 5000 loss:  1.2258808612823486\n",
      "Epoch 6000 loss:  2.56320858001709\n",
      "Epoch 7000 loss:  0.8220564126968384\n",
      "Epoch 8000 loss:  0.6012448668479919\n",
      "Epoch 9000 loss:  0.5728933811187744\n",
      "Epoch 10000 loss:  0.5458008050918579\n",
      "R-Squared: 0.975, MAE: 0.89\n",
      "R-Squared: 0.701, MAE: 2.91\n"
     ]
    }
   ],
   "source": [
    "# overfitting\n",
    "foo.model_pytorch = Net(foo.cols, l1=256, l2=256, l3=10, l4=10, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abyCbuUoiEDA"
   },
   "source": [
    "##### Round Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28557,
     "status": "ok",
     "timestamp": 1669962937276,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "YtpX3l-DiHbK",
    "outputId": "8c68ccd8-3de7-45ba-d00d-836a726a8766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  2.1545987129211426\n",
      "Epoch 2000 loss:  1.9172662496566772\n",
      "Epoch 3000 loss:  1.6381511688232422\n",
      "Epoch 4000 loss:  1.0400948524475098\n",
      "Epoch 5000 loss:  1.1169161796569824\n",
      "Epoch 6000 loss:  1.1672966480255127\n",
      "Epoch 7000 loss:  1.0325645208358765\n",
      "Epoch 8000 loss:  0.9722885489463806\n",
      "Epoch 9000 loss:  0.8285640478134155\n",
      "Epoch 10000 loss:  0.8253082633018494\n",
      "R-Squared: 0.950, MAE: 1.20\n",
      "R-Squared: 0.691, MAE: 2.78\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=1, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30651,
     "status": "ok",
     "timestamp": 1669962994777,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "3DdjeXeUiHoL",
    "outputId": "cc83cb5f-1618-4928-fb69-2810ec9aa3f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  2.1702609062194824\n",
      "Epoch 2000 loss:  1.7178232669830322\n",
      "Epoch 3000 loss:  1.5234358310699463\n",
      "Epoch 4000 loss:  1.3641221523284912\n",
      "Epoch 5000 loss:  1.1590920686721802\n",
      "Epoch 6000 loss:  1.0540438890457153\n",
      "Epoch 7000 loss:  1.054677963256836\n",
      "Epoch 8000 loss:  0.8930981159210205\n",
      "Epoch 9000 loss:  0.9064716100692749\n",
      "Epoch 10000 loss:  0.6914174556732178\n",
      "R-Squared: 0.945, MAE: 1.11\n",
      "R-Squared: 0.766, MAE: 2.78\n"
     ]
    }
   ],
   "source": [
    "# candidate - current best \n",
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28414,
     "status": "ok",
     "timestamp": 1669963046582,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "zo-Ekj4XiHpu",
    "outputId": "4152535d-181d-4e96-8005-4258986a1ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  3.3903427124023438\n",
      "Epoch 2000 loss:  2.213636875152588\n",
      "Epoch 3000 loss:  1.8323246240615845\n",
      "Epoch 4000 loss:  1.6143088340759277\n",
      "Epoch 5000 loss:  1.3897013664245605\n",
      "Epoch 6000 loss:  1.3323924541473389\n",
      "Epoch 7000 loss:  1.1653300523757935\n",
      "Epoch 8000 loss:  1.1334720849990845\n",
      "Epoch 9000 loss:  1.0416122674942017\n",
      "Epoch 10000 loss:  1.1418401002883911\n",
      "R-Squared: 0.925, MAE: 1.40\n",
      "R-Squared: 0.711, MAE: 2.72\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0003, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27906,
     "status": "ok",
     "timestamp": 1669963174991,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "DsFSYv5rjgO6",
    "outputId": "51cc6376-2ebd-4c36-99e8-838833d6c4a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  3.217740058898926\n",
      "Epoch 2000 loss:  2.14133882522583\n",
      "Epoch 3000 loss:  1.804438591003418\n",
      "Epoch 4000 loss:  1.6042677164077759\n",
      "Epoch 5000 loss:  1.4114569425582886\n",
      "Epoch 6000 loss:  1.4309982061386108\n",
      "Epoch 7000 loss:  1.301927089691162\n",
      "Epoch 8000 loss:  1.1724416017532349\n",
      "Epoch 9000 loss:  1.245043158531189\n",
      "Epoch 10000 loss:  1.11747407913208\n",
      "R-Squared: 0.911, MAE: 1.52\n",
      "R-Squared: 0.701, MAE: 2.96\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0003, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HWOYbrZkHoA"
   },
   "source": [
    "##### Round Five - final round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30939,
     "status": "ok",
     "timestamp": 1669963583399,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "W-9DcUU-kKNo",
    "outputId": "260fa975-6a19-48db-add1-e109cd759ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  2.6856229305267334\n",
      "Epoch 2000 loss:  1.8495086431503296\n",
      "Epoch 3000 loss:  1.8609514236450195\n",
      "Epoch 4000 loss:  1.566051959991455\n",
      "Epoch 5000 loss:  1.6632754802703857\n",
      "Epoch 6000 loss:  1.2772905826568604\n",
      "Epoch 7000 loss:  1.1303715705871582\n",
      "Epoch 8000 loss:  1.168574571609497\n",
      "Epoch 9000 loss:  0.8516449928283691\n",
      "Epoch 10000 loss:  0.8078053593635559\n",
      "R-Squared: 0.949, MAE: 1.27\n",
      "R-Squared: 0.719, MAE: 2.75\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=250, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72798,
     "status": "ok",
     "timestamp": 1669963671458,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "2zSYVwX4kbt-",
    "outputId": "49f5452f-fae2-47f0-ad61-834a70a92c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  5.113327741622925\n",
      "Epoch 2000 loss:  3.880610227584839\n",
      "Epoch 3000 loss:  3.9647854566574097\n",
      "Epoch 4000 loss:  3.136811673641205\n",
      "Epoch 5000 loss:  3.622177839279175\n",
      "Epoch 6000 loss:  2.1241248846054077\n",
      "Epoch 7000 loss:  2.478312373161316\n",
      "Epoch 8000 loss:  2.261405050754547\n",
      "Epoch 9000 loss:  1.9742512106895447\n",
      "Epoch 10000 loss:  1.709864854812622\n",
      "R-Squared: 0.975, MAE: 0.87\n",
      "R-Squared: 0.757, MAE: 2.63\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=100, num_epochs=10000, learning_rate=0.0005, criterion=torch.nn.HuberLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147092,
     "status": "ok",
     "timestamp": 1669964160765,
     "user": {
      "displayName": "francisco sun",
      "userId": "06631609821688815870"
     },
     "user_tz": 300
    },
    "id": "715KQ8yMlmp5",
    "outputId": "044cfb42-8f96-4a8e-8200-0aeb6680eef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss:  18.70051610469818\n",
      "Epoch 2000 loss:  13.241290926933289\n",
      "Epoch 3000 loss:  11.263829112052917\n",
      "Epoch 4000 loss:  10.161400437355042\n",
      "Epoch 5000 loss:  9.912397384643555\n",
      "Epoch 6000 loss:  8.679338991641998\n",
      "Epoch 7000 loss:  9.112246870994568\n",
      "Epoch 8000 loss:  7.307150781154633\n",
      "Epoch 9000 loss:  6.745783269405365\n",
      "Epoch 10000 loss:  6.2382559180259705\n",
      "R-Squared: 0.931, MAE: 1.25\n",
      "R-Squared: 0.708, MAE: 2.75\n"
     ]
    }
   ],
   "source": [
    "foo.model_pytorch = Net(foo.cols, l1=128, l2=32, l3=64, l4=16, l5=4, l6=4, output=1)\n",
    "foo.eval(batch_size=50, num_epochs=10000, learning_rate=0.0001, criterion=torch.nn.HuberLoss())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
