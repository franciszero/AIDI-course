{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e143fd6",
   "metadata": {},
   "source": [
    "# Action Space\n",
    "\n",
    "The action is a ndarray with shape (1,) which can take values {0, 1} indicating the direction of the fixed force the cart is pushed with.\n",
    "\n",
    "0: Push cart to the left\n",
    "\n",
    "1: Push cart to the right\n",
    "\n",
    "Note: The velocity that is reduced or increased by the applied force is not fixed and it depends on the angle the pole is pointing. The center of gravity of the pole varies the amount of energy needed to move the cart underneath it\n",
    "\n",
    "Observation Space\n",
    "The observation is a ndarray with shape (4,) with the values corresponding to the following positions and velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde8608",
   "metadata": {},
   "source": [
    "# We will use CartPole environment provided by gym, an opensource python library which provides many environments for Reinforcement Learning such as Atari Games. In CartPole, we have a pole standing on a cart which can move. The goal of the agent is to keep the pole up by applying some force on it every time step. When the pole is less than 15° from the vertical, the agent receives a reward of 1. An episode is ended when the pole is more than 15° far from the vertical or when the cart position exceeds 2.4 units from the centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea231f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " conda install -c conda-forge tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d588dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Applications/Anaconda/anaconda3/lib/python3.8/site-packages (1.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8a9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da0538",
   "metadata": {},
   "source": [
    "The agent has to:\n",
    "\n",
    "1.compute the action to choose for a given state\n",
    "2.store its experiences in a memory buffer\n",
    "3.train the DNN by sampling a batch of experiences from the memory buffer\n",
    "\n",
    "The agent is more likely to explore the environment in the beginning by choosing random actions because he has no idea about how the environment works. Through time steps, the agent gets more and more knowledge, so he is more likely to exploit his knowledge rather than picking random actions. For that purpose, we will use the epsilon greedy algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8337741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.n_actions = action_size\n",
    "        # we define some parameters and hyperparameters:\n",
    "        # \"lr\" : learning rate\n",
    "        # \"gamma\": discounted factor\n",
    "        # \"exploration_proba_decay\": decay of the exploration probability\n",
    "        # \"batch_size\": size of experiences we sample to train the DNN\n",
    "        self.lr = 0.001\n",
    "        self.gamma = 0.99\n",
    "        self.exploration_proba = 1.0\n",
    "        self.exploration_proba_decay = 0.005\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        # We define our memory buffer where we will store our experiences\n",
    "        # We stores only the 2000 last time steps\n",
    "        self.memory_buffer= list()\n",
    "        self.max_memory_buffer = 2000\n",
    "        \n",
    "        # We creaate our model having to hidden layers of 24 units (neurones)\n",
    "        # The first layer has the same size as a state size\n",
    "        # The last layer has the size of actions space\n",
    "        self.model = Sequential([\n",
    "            Dense(units=24,input_dim=state_size, activation = 'relu'),\n",
    "            Dense(units=24,activation = 'relu'),\n",
    "            Dense(units=action_size, activation = 'linear')\n",
    "        ])\n",
    "        self.model.compile(loss=\"mse\",\n",
    "                      optimizer = Adam(lr=self.lr))\n",
    "        \n",
    "    # The agent computes the action to perform given a state \n",
    "    def compute_action(self, current_state):\n",
    "        # We sample a variable uniformly over [0,1]\n",
    "        # if the variable is less than the exploration probability\n",
    "        #     we choose an action randomly\n",
    "        # else\n",
    "        #     we forward the state through the DNN and choose the action \n",
    "        #     with the highest Q-value.\n",
    "        if np.random.uniform(0,1) < self.exploration_proba:\n",
    "            return np.random.choice(range(self.n_actions))\n",
    "        q_values = self.model.predict(current_state, verbose=0)[0]\n",
    "        # print(\"This is qvalues:\",q_values)\n",
    "        return np.argmax(q_values)\n",
    "\n",
    "    # when an episode is finished, we update the exploration probability using \n",
    "    # espilon greedy algorithm\n",
    "    def update_exploration_probability(self):\n",
    "        self.exploration_proba = self.exploration_proba * np.exp(-self.exploration_proba_decay)\n",
    "        print(self.exploration_proba)\n",
    "    \n",
    "    # At each time step, we store the corresponding experience\n",
    "    def store_episode(self,current_state, action, reward, next_state, done):\n",
    "        #We use a dictionnary to store them\n",
    "        self.memory_buffer.append({\n",
    "            \"current_state\":current_state,\n",
    "            \"action\":action,\n",
    "            \"reward\":reward,\n",
    "            \"next_state\":next_state,\n",
    "            \"done\" :done\n",
    "        })\n",
    "        # If the size of memory buffer exceeds its maximum, we remove the oldest experience\n",
    "        if len(self.memory_buffer) > self.max_memory_buffer:\n",
    "            self.memory_buffer.pop(0)\n",
    "    \n",
    "\n",
    "    # At the end of each episode, we train our model\n",
    "    def train(self):\n",
    "        # We shuffle the memory buffer and select a batch size of experiences\n",
    "        np.random.shuffle(self.memory_buffer)\n",
    "        batch_sample = self.memory_buffer[0:self.batch_size]\n",
    "        \n",
    "        # We iterate over the selected experiences\n",
    "        for experience in batch_sample:\n",
    "            # We compute the Q-values of S_t\n",
    "            q_current_state = self.model.predict(experience[\"current_state\"])\n",
    "           \n",
    "            # We compute the Q-target using Bellman optimality equation\n",
    "            q_target = experience[\"reward\"]\n",
    "            \n",
    "            if not experience[\"done\"]:\n",
    "                q_target = q_target + self.gamma*np.max(self.model.predict(experience[\"next_state\"])[0])\n",
    "            print(\"+++++++++++++++++\", len(q_current_state[0]), \"+++++++++++++\", experience[\"action\"])\n",
    "            q_current_state[0][experience[\"action\"]] = q_target\n",
    "            # train the model\n",
    "            self.model.fit(experience[\"current_state\"], q_current_state, verbose=0)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c03ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our gym environment \n",
    "env = gym.make(\"CartPole-v1\")\n",
    "# We get the shape of a state and the actions space size\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "# Number of episodes to run\n",
    "n_episodes = 500\n",
    "# Max iterations per epiode\n",
    "max_iteration_ep = 1000\n",
    "# We define our agent\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e0c0f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7acfdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "423393be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10228420671553794\n",
      "episodes: 0\n",
      "0.1017740621062842\n",
      "episodes: 1\n",
      "0.10126646185388387\n",
      "episodes: 2\n",
      "0.10076139326830418\n",
      "episodes: 3\n",
      "0.10025884372280419\n",
      "episodes: 4\n",
      "0.0997588006536191\n",
      "episodes: 5\n",
      "0.09926125155964612\n",
      "episodes: 6\n",
      "0.09876618400213198\n",
      "episodes: 7\n",
      "0.09827358560436199\n",
      "episodes: 8\n",
      "0.09778344405135052\n",
      "episodes: 9\n",
      "0.09729574708953323\n",
      "episodes: 10\n",
      "0.09681048252646067\n",
      "episodes: 11\n",
      "0.09632763823049348\n",
      "episodes: 12\n",
      "0.09584720213049912\n",
      "episodes: 13\n",
      "0.09536916221555007\n",
      "episodes: 14\n",
      "0.09489350653462356\n",
      "episodes: 15\n",
      "0.09442022319630279\n",
      "episodes: 16\n",
      "0.09394930036847965\n",
      "episodes: 17\n",
      "0.09348072627805892\n",
      "episodes: 18\n",
      "0.09301448921066394\n",
      "episodes: 19\n",
      "0.09255057751034372\n",
      "episodes: 20\n",
      "0.09208897957928161\n",
      "episodes: 21\n",
      "0.0916296838775053\n",
      "episodes: 22\n",
      "0.0911726789225983\n",
      "episodes: 23\n",
      "0.09071795328941294\n",
      "episodes: 24\n",
      "0.09026549560978472\n",
      "episodes: 25\n",
      "0.08981529457224809\n",
      "episodes: 26\n",
      "0.08936733892175364\n",
      "episodes: 27\n",
      "0.08892161745938677\n",
      "episodes: 28\n",
      "0.08847811904208774\n",
      "episodes: 29\n",
      "0.088036832582373\n",
      "episodes: 30\n",
      "0.08759774704805807\n",
      "episodes: 31\n",
      "0.08716085146198173\n",
      "episodes: 32\n",
      "0.08672613490173157\n",
      "episodes: 33\n",
      "0.08629358649937095\n",
      "episodes: 34\n",
      "0.08586319544116727\n",
      "episodes: 35\n",
      "0.08543495096732166\n",
      "episodes: 36\n",
      "0.08500884237169998\n",
      "episodes: 37\n",
      "0.08458485900156514\n",
      "episodes: 38\n",
      "0.08416299025731079\n",
      "episodes: 39\n",
      "0.08374322559219638\n",
      "episodes: 40\n",
      "0.0833255545120834\n",
      "episodes: 41\n",
      "0.0829099665751731\n",
      "episodes: 42\n",
      "0.08249645139174541\n",
      "episodes: 43\n",
      "0.08208499862389922\n",
      "episodes: 44\n",
      "0.08167559798529388\n",
      "episodes: 45\n",
      "0.0812682392408921\n",
      "episodes: 46\n",
      "0.08086291220670408\n",
      "episodes: 47\n",
      "0.08045960674953284\n",
      "episodes: 48\n",
      "0.08005831278672094\n",
      "episodes: 49\n",
      "0.07965902028589843\n",
      "episodes: 50\n",
      "0.07926171926473197\n",
      "episodes: 51\n",
      "0.07886639979067535\n",
      "episodes: 52\n",
      "0.07847305198072112\n",
      "episodes: 53\n",
      "0.07808166600115354\n",
      "episodes: 54\n",
      "0.07769223206730276\n",
      "episodes: 55\n",
      "0.07730474044330013\n",
      "episodes: 56\n",
      "0.07691918144183488\n",
      "episodes: 57\n",
      "0.07653554542391189\n",
      "episodes: 58\n",
      "0.07615382279861072\n",
      "episodes: 59\n",
      "0.07577400402284586\n",
      "episodes: 60\n",
      "0.07539607960112814\n",
      "episodes: 61\n",
      "0.07502004008532732\n",
      "episodes: 62\n",
      "0.07464587607443594\n",
      "episodes: 63\n",
      "0.07427357821433424\n",
      "episodes: 64\n",
      "0.07390313719755631\n",
      "episodes: 65\n",
      "0.07353454376305744\n",
      "episodes: 66\n",
      "0.07316778869598259\n",
      "episodes: 67\n",
      "0.07280286282743595\n",
      "episodes: 68\n",
      "0.07243975703425182\n",
      "episodes: 69\n",
      "0.07207846223876645\n",
      "episodes: 70\n",
      "0.07171896940859114\n",
      "episodes: 71\n",
      "0.07136126955638641\n",
      "episodes: 72\n",
      "0.07100535373963733\n",
      "episodes: 73\n",
      "0.07065121306042994\n",
      "episodes: 74\n",
      "0.07029883866522882\n",
      "episodes: 75\n",
      "0.06994822174465572\n",
      "episodes: 76\n",
      "0.06959935353326938\n",
      "episodes: 77\n",
      "0.06925222530934634\n",
      "episodes: 78\n",
      "0.06890682839466293\n",
      "episodes: 79\n",
      "0.06856315415427829\n",
      "episodes: 80\n",
      "0.0682211939963185\n",
      "episodes: 81\n",
      "0.0678809393717618\n",
      "episodes: 82\n",
      "0.06754238177422488\n",
      "episodes: 83\n",
      "0.06720551273975013\n",
      "episodes: 84\n",
      "0.06687032384659418\n",
      "episodes: 85\n",
      "0.06653680671501722\n",
      "episodes: 86\n",
      "0.06620495300707359\n",
      "episodes: 87\n",
      "0.06587475442640332\n",
      "episodes: 88\n",
      "0.0655462027180247\n",
      "episodes: 89\n",
      "0.06521928966812789\n",
      "episodes: 90\n",
      "0.06489400710386962\n",
      "episodes: 91\n",
      "0.06457034689316886\n",
      "episodes: 92\n",
      "0.06424830094450346\n",
      "episodes: 93\n",
      "0.06392786120670793\n",
      "episodes: 94\n",
      "0.06360901966877217\n",
      "episodes: 95\n",
      "0.06329176835964108\n",
      "episodes: 96\n",
      "0.06297609934801544\n",
      "episodes: 97\n",
      "0.06266200474215351\n",
      "episodes: 98\n",
      "0.062349476689673784\n",
      "episodes: 99\n",
      "0.062038507377358665\n",
      "episodes: 100\n",
      "0.06172908903095916\n",
      "episodes: 101\n",
      "0.06142121391500049\n",
      "episodes: 102\n",
      "0.06111487433258871\n",
      "episodes: 103\n",
      "0.06081006262521832\n",
      "episodes: 104\n",
      "0.06050677117258075\n",
      "episodes: 105\n",
      "0.060204992392373896\n",
      "episodes: 106\n",
      "0.05990471874011253\n",
      "episodes: 107\n",
      "0.05960594270893971\n",
      "episodes: 108\n",
      "0.05930865682943909\n",
      "episodes: 109\n",
      "0.059012853669448195\n",
      "episodes: 110\n",
      "0.05871852583387263\n",
      "episodes: 111\n",
      "0.05842566596450117\n",
      "episodes: 112\n",
      "0.058134266739821826\n",
      "episodes: 113\n",
      "0.05784432087483881\n",
      "episodes: 114\n",
      "0.05755582112089039\n",
      "episodes: 115\n",
      "0.05726876026546769\n",
      "episodes: 116\n",
      "0.05698313113203438\n",
      "episodes: 117\n",
      "0.05669892657984725\n",
      "episodes: 118\n",
      "0.05641613950377768\n",
      "episodes: 119\n",
      "0.05613476283413406\n",
      "episodes: 120\n",
      "0.05585478953648497\n",
      "episodes: 121\n",
      "0.0555762126114834\n",
      "episodes: 122\n",
      "0.055299025094691714\n",
      "episodes: 123\n",
      "0.05502322005640756\n",
      "episodes: 124\n",
      "0.054748790601490606\n",
      "episodes: 125\n",
      "0.05447572986919019\n",
      "episodes: 126\n",
      "0.05420403103297379\n",
      "episodes: 127\n",
      "0.05393368730035634\n",
      "episodes: 128\n",
      "0.05366469191273045\n",
      "episodes: 129\n",
      "0.05339703814519741\n",
      "episodes: 130\n",
      "0.0531307193063991\n",
      "episodes: 131\n",
      "0.05286572873835068\n",
      "episodes: 132\n",
      "0.052602059816274145\n",
      "episodes: 133\n",
      "0.05233970594843271\n",
      "episodes: 134\n",
      "0.05207866057596601\n",
      "episodes: 135\n",
      "0.051818917172726145\n",
      "episodes: 136\n",
      "0.0515604692451145\n",
      "episodes: 137\n",
      "0.051303310331919434\n",
      "episodes: 138\n",
      "0.05104743400415471\n",
      "episodes: 139\n",
      "0.05079283386489881\n",
      "episodes: 140\n",
      "0.050539503549134994\n",
      "episodes: 141\n",
      "0.05028743672359218\n",
      "episodes: 142\n",
      "0.05003662708658659\n",
      "episodes: 143\n",
      "0.04978706836786424\n",
      "episodes: 144\n",
      "0.04953875432844417\n",
      "episodes: 145\n",
      "0.049291678760462455\n",
      "episodes: 146\n",
      "0.04904583548701703\n",
      "episodes: 147\n",
      "0.048801218362013246\n",
      "episodes: 148\n",
      "0.04855782127001025\n",
      "episodes: 149\n",
      "0.04831563812606806\n",
      "episodes: 150\n",
      "0.04807466287559546\n",
      "episodes: 151\n",
      "0.047834889494198646\n",
      "episodes: 152\n",
      "0.04759631198753059\n",
      "episodes: 153\n",
      "0.04735892439114119\n",
      "episodes: 154\n",
      "0.04712272077032819\n",
      "episodes: 155\n",
      "0.046887695219988756\n",
      "episodes: 156\n",
      "0.04665384186447189\n",
      "episodes: 157\n",
      "0.04642115485743153\n",
      "episodes: 158\n",
      "0.04618962838168037\n",
      "episodes: 159\n",
      "0.04595925664904447\n",
      "episodes: 160\n",
      "0.04573003390021851\n",
      "episodes: 161\n",
      "0.045501954404621826\n",
      "episodes: 162\n",
      "0.04527501246025516\n",
      "episodes: 163\n",
      "0.045049202393558065\n",
      "episodes: 164\n",
      "0.044824518559267126\n",
      "episodes: 165\n",
      "0.044600955340274785\n",
      "episodes: 166\n",
      "0.04437850714748892\n",
      "episodes: 167\n",
      "0.044157168419693124\n",
      "episodes: 168\n",
      "0.04393693362340767\n",
      "episodes: 169\n",
      "0.04371779725275119\n",
      "episodes: 170\n",
      "0.043499753829302996\n",
      "episodes: 171\n",
      "0.04328279790196615\n",
      "episodes: 172\n",
      "0.04306692404683117\n",
      "episodes: 173\n",
      "0.04285212686704043\n",
      "episodes: 174\n",
      "0.04263840099265325\n",
      "episodes: 175\n",
      "0.042425741080511635\n",
      "episodes: 176\n",
      "0.04221414181410671\n",
      "episodes: 177\n",
      "0.042003597903445794\n",
      "episodes: 178\n",
      "0.04179410408492015\n",
      "episodes: 179\n",
      "0.04158565512117341\n",
      "episodes: 180\n",
      "0.041378245800970624\n",
      "episodes: 181\n",
      "0.041171870939067975\n",
      "episodes: 182\n",
      "0.040966525376083175\n",
      "episodes: 183\n",
      "0.040762203978366454\n",
      "episodes: 184\n",
      "0.04055890163787222\n",
      "episodes: 185\n",
      "0.04035661327203138\n",
      "episodes: 186\n",
      "0.040155333823624254\n",
      "episodes: 187\n",
      "0.03995505826065414\n",
      "episodes: 188\n",
      "0.03975578157622153\n",
      "episodes: 189\n",
      "0.039557498788398954\n",
      "episodes: 190\n",
      "0.03936020494010637\n",
      "episodes: 191\n",
      "0.0391638950989873\n",
      "episodes: 192\n",
      "0.0389685643572855\n",
      "episodes: 193\n",
      "0.03877420783172224\n",
      "episodes: 194\n",
      "0.03858082066337426\n",
      "episodes: 195\n",
      "0.03838839801755229\n",
      "episodes: 196\n",
      "0.038196935083680154\n",
      "episodes: 197\n",
      "0.038006427075174536\n",
      "episodes: 198\n",
      "0.0378168692293253\n",
      "episodes: 199\n",
      "0.03762825680717643\n",
      "episodes: 200\n",
      "0.037440585093407544\n",
      "episodes: 201\n",
      "0.037253849396216024\n",
      "episodes: 202\n",
      "0.03706804504719972\n",
      "episodes: 203\n",
      "0.036883167401240216\n",
      "episodes: 204\n",
      "0.03669921183638675\n",
      "episodes: 205\n",
      "0.03651617375374061\n",
      "episodes: 206\n",
      "0.036334048577340204\n",
      "episodes: 207\n",
      "0.03615283175404663\n",
      "episodes: 208\n",
      "0.03597251875342986\n",
      "episodes: 209\n",
      "0.035793105067655505\n",
      "episodes: 210\n",
      "0.03561458621137206\n",
      "episodes: 211\n",
      "0.035436957721598834\n",
      "episodes: 212\n",
      "0.03526021515761432\n",
      "episodes: 213\n",
      "0.03508435410084522\n",
      "episodes: 214\n",
      "0.03490937015475595\n",
      "episodes: 215\n",
      "0.03473525894473875\n",
      "episodes: 216\n",
      "0.0345620161180043\n",
      "episodes: 217\n",
      "0.034389637343472904\n",
      "episodes: 218\n",
      "0.034218118311666226\n",
      "episodes: 219\n",
      "0.03404745473459953\n",
      "episodes: 220\n",
      "0.03387764234567451\n",
      "episodes: 221\n",
      "0.03370867689957259\n",
      "episodes: 222\n",
      "0.03354055417214882\n",
      "episodes: 223\n",
      "0.03337326996032627\n",
      "episodes: 224\n",
      "0.03320682008199091\n",
      "episodes: 225\n",
      "0.03304120037588713\n",
      "episodes: 226\n",
      "0.032876406701513636\n",
      "episodes: 227\n",
      "0.03271243493902\n",
      "episodes: 228\n",
      "0.03254928098910361\n",
      "episodes: 229\n",
      "0.03238694077290723\n",
      "episodes: 230\n",
      "0.03222541023191699\n",
      "episodes: 231\n",
      "0.032064685327860956\n",
      "episodes: 232\n",
      "0.031904762042608156\n",
      "episodes: 233\n",
      "0.031745636378068126\n",
      "episodes: 234\n",
      "0.03158730435609097\n",
      "episodes: 235\n",
      "0.03142976201836789\n",
      "episodes: 236\n",
      "0.03127300542633224\n",
      "episodes: 237\n",
      "0.03111703066106105\n",
      "episodes: 238\n",
      "0.030961833823177066\n",
      "episodes: 239\n",
      "0.030807411032751256\n",
      "episodes: 240\n",
      "0.03065375842920582\n",
      "episodes: 241\n",
      "0.030500872171217667\n",
      "episodes: 242\n",
      "0.030348748436622382\n",
      "episodes: 243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030197383422318678\n",
      "episodes: 244\n",
      "0.030046773344173314\n",
      "episodes: 245\n",
      "0.02989691443692649\n",
      "episodes: 246\n",
      "0.029747802954097725\n",
      "episodes: 247\n",
      "0.029599435167892176\n",
      "episodes: 248\n",
      "0.029451807369107463\n",
      "episodes: 249\n",
      "0.029304915867040926\n",
      "episodes: 250\n",
      "0.029158756989397364\n",
      "episodes: 251\n",
      "0.029013327082197223\n",
      "episodes: 252\n",
      "0.028868622509685252\n",
      "episodes: 253\n",
      "0.028724639654239596\n",
      "episodes: 254\n",
      "0.028581374916281373\n",
      "episodes: 255\n",
      "0.02843882471418467\n",
      "episodes: 256\n",
      "0.028296985484187014\n",
      "episodes: 257\n",
      "0.028155853680300266\n",
      "episodes: 258\n",
      "0.028015425774221975\n",
      "episodes: 259\n",
      "0.02787569825524718\n",
      "episodes: 260\n",
      "0.027736667630180623\n",
      "episodes: 261\n",
      "0.027598330423249443\n",
      "episodes: 262\n",
      "0.027460683176016257\n",
      "episodes: 263\n",
      "0.02732372244729272\n",
      "episodes: 264\n",
      "0.027187444813053473\n",
      "episodes: 265\n",
      "0.02705184686635057\n",
      "episodes: 266\n",
      "0.026916925217228275\n",
      "episodes: 267\n",
      "0.026782676492638335\n",
      "episodes: 268\n",
      "0.02664909733635564\n",
      "episodes: 269\n",
      "0.026516184408894333\n",
      "episodes: 270\n",
      "0.0263839343874243\n",
      "episodes: 271\n",
      "0.026252343965688117\n",
      "episodes: 272\n",
      "0.026121409853918386\n",
      "episodes: 273\n",
      "0.025991128778755493\n",
      "episodes: 274\n",
      "0.025861497483165775\n",
      "episodes: 275\n",
      "0.025732512726360093\n",
      "episodes: 276\n",
      "0.025604171283712805\n",
      "episodes: 277\n",
      "0.025476469946681162\n",
      "episodes: 278\n",
      "0.025349405522725087\n",
      "episodes: 279\n",
      "0.02522297483522736\n",
      "episodes: 280\n",
      "0.025097174723414214\n",
      "episodes: 281\n",
      "0.024972002042276297\n",
      "episodes: 282\n",
      "0.024847453662490065\n",
      "episodes: 283\n",
      "0.024723526470339534\n",
      "episodes: 284\n",
      "0.024600217367638445\n",
      "episodes: 285\n",
      "0.02447752327165281\n",
      "episodes: 286\n",
      "0.024355441115023836\n",
      "episodes: 287\n",
      "0.024233967845691255\n",
      "episodes: 288\n",
      "0.024113100426817004\n",
      "episodes: 289\n",
      "0.023992835836709313\n",
      "episodes: 290\n",
      "0.02387317106874717\n",
      "episodes: 291\n",
      "0.02375410313130514\n",
      "episodes: 292\n",
      "0.023635629047678585\n",
      "episodes: 293\n",
      "0.023517745856009246\n",
      "episodes: 294\n",
      "0.02340045060921119\n",
      "episodes: 295\n",
      "0.023283740374897142\n",
      "episodes: 296\n",
      "0.023167612235305158\n",
      "episodes: 297\n",
      "0.023052063287225706\n",
      "episodes: 298\n",
      "0.022937090641929062\n",
      "episodes: 299\n",
      "0.02282269142509311\n",
      "episodes: 300\n",
      "0.022708862776731467\n",
      "episodes: 301\n",
      "0.022595601851121996\n",
      "episodes: 302\n",
      "0.02248290581673566\n",
      "episodes: 303\n",
      "0.022370771856165726\n",
      "episodes: 304\n",
      "0.022259197166057343\n",
      "episodes: 305\n",
      "0.022148178957037447\n",
      "episodes: 306\n",
      "0.022037714453645028\n",
      "episodes: 307\n",
      "0.02192780089426175\n",
      "episodes: 308\n",
      "0.021818435531042898\n",
      "episodes: 309\n",
      "0.021709615629848703\n",
      "episodes: 310\n",
      "0.021601338470175962\n",
      "episodes: 311\n",
      "0.021493601345090048\n",
      "episodes: 312\n",
      "0.02138640156115722\n",
      "episodes: 313\n",
      "0.021279736438377297\n",
      "episodes: 314\n",
      "0.021173603310116654\n",
      "episodes: 315\n",
      "0.021067999523041555\n",
      "episodes: 316\n",
      "0.020962922437051827\n",
      "episodes: 317\n",
      "0.020858369425214844\n",
      "episodes: 318\n",
      "0.020754337873699867\n",
      "episodes: 319\n",
      "0.020650825181712688\n",
      "episodes: 320\n",
      "0.020547828761430617\n",
      "episodes: 321\n",
      "0.02044534603793778\n",
      "episodes: 322\n",
      "0.020343374449160755\n",
      "episodes: 323\n",
      "0.02024191144580451\n",
      "episodes: 324\n",
      "0.02014095449128868\n",
      "episodes: 325\n",
      "0.02004050106168414\n",
      "episodes: 326\n",
      "0.019940548645649918\n",
      "episodes: 327\n",
      "0.01984109474437041\n",
      "episodes: 328\n",
      "0.0197421368714929\n",
      "episodes: 329\n",
      "0.019643672553065414\n",
      "episodes: 330\n",
      "0.019545699327474866\n",
      "episodes: 331\n",
      "0.01944821474538551\n",
      "episodes: 332\n",
      "0.019351216369677716\n",
      "episodes: 333\n",
      "0.019254701775387042\n",
      "episodes: 334\n",
      "0.0191586685496436\n",
      "episodes: 335\n",
      "0.01906311429161175\n",
      "episodes: 336\n",
      "0.018968036612430062\n",
      "episodes: 337\n",
      "0.018873433135151604\n",
      "episodes: 338\n",
      "0.018779301494684517\n",
      "episodes: 339\n",
      "0.018685639337732887\n",
      "episodes: 340\n",
      "0.01859244432273791\n",
      "episodes: 341\n",
      "0.01849971411981936\n",
      "episodes: 342\n",
      "0.018407446410717333\n",
      "episodes: 343\n",
      "0.018315638888734293\n",
      "episodes: 344\n",
      "0.018224289258677414\n",
      "episodes: 345\n",
      "0.018133395236801183\n",
      "episodes: 346\n",
      "0.01804295455075032\n",
      "episodes: 347\n",
      "0.017952964939502967\n",
      "episodes: 348\n",
      "0.017863424153314152\n",
      "episodes: 349\n",
      "0.017774329953659556\n",
      "episodes: 350\n",
      "0.017685680113179548\n",
      "episodes: 351\n",
      "0.0175974724156235\n",
      "episodes: 352\n",
      "0.017509704655794378\n",
      "episodes: 353\n",
      "0.017422374639493615\n",
      "episodes: 354\n",
      "0.017335480183466256\n",
      "episodes: 355\n",
      "0.017249019115346376\n",
      "episodes: 356\n",
      "0.017162989273602765\n",
      "episodes: 357\n",
      "0.0170773885074849\n",
      "episodes: 358\n",
      "0.01699221467696917\n",
      "episodes: 359\n",
      "0.01690746565270538\n",
      "episodes: 360\n",
      "0.016823139315963503\n",
      "episodes: 361\n",
      "0.01673923355858073\n",
      "episodes: 362\n",
      "0.016655746282908758\n",
      "episodes: 363\n",
      "0.016572675401761345\n",
      "episodes: 364\n",
      "0.01649001883836214\n",
      "episodes: 365\n",
      "0.016407774526292745\n",
      "episodes: 366\n",
      "0.016325940409441082\n",
      "episodes: 367\n",
      "0.016244514441949968\n",
      "episodes: 368\n",
      "0.01616349458816597\n",
      "episodes: 369\n",
      "0.016082878822588527\n",
      "episodes: 370\n",
      "0.016002665129819297\n",
      "episodes: 371\n",
      "0.015922851504511785\n",
      "episodes: 372\n",
      "0.015843435951321202\n",
      "episodes: 373\n",
      "0.015764416484854583\n",
      "episodes: 374\n",
      "0.015685791129621148\n",
      "episodes: 375\n",
      "0.015607557919982924\n",
      "episodes: 376\n",
      "0.015529714900105594\n",
      "episodes: 377\n",
      "0.015452260123909605\n",
      "episodes: 378\n",
      "0.015375191655021521\n",
      "episodes: 379\n",
      "0.015298507566725605\n",
      "episodes: 380\n",
      "0.015222205941915654\n",
      "episodes: 381\n",
      "0.015146284873047075\n",
      "episodes: 382\n",
      "0.015070742462089191\n",
      "episodes: 383\n",
      "0.014995576820477795\n",
      "episodes: 384\n",
      "0.014920786069067932\n",
      "episodes: 385\n",
      "0.01484636833808692\n",
      "episodes: 386\n",
      "0.014772321767087608\n",
      "episodes: 387\n",
      "0.014698644504901867\n",
      "episodes: 388\n",
      "0.014625334709594304\n",
      "episodes: 389\n",
      "0.014552390548416217\n",
      "episodes: 390\n",
      "0.014479810197759778\n",
      "episodes: 391\n",
      "0.01440759184311244\n",
      "episodes: 392\n",
      "0.014335733679011576\n",
      "episodes: 393\n",
      "0.01426423390899934\n",
      "episodes: 394\n",
      "0.01419309074557776\n",
      "episodes: 395\n",
      "0.014122302410164043\n",
      "episodes: 396\n",
      "0.014051867133046117\n",
      "episodes: 397\n",
      "0.013981783153338386\n",
      "episodes: 398\n",
      "0.013912048718937708\n",
      "episodes: 399\n",
      "0.01384266208647959\n",
      "episodes: 400\n",
      "0.013773621521294604\n",
      "episodes: 401\n",
      "0.013704925297365028\n",
      "episodes: 402\n",
      "0.013636571697281686\n",
      "episodes: 403\n",
      "0.013568559012201014\n",
      "episodes: 404\n",
      "0.013500885541802343\n",
      "episodes: 405\n",
      "0.01343354959424539\n",
      "episodes: 406\n",
      "0.013366549486127957\n",
      "episodes: 407\n",
      "0.013299883542443852\n",
      "episodes: 408\n",
      "0.013233550096541011\n",
      "episodes: 409\n",
      "0.013167547490079833\n",
      "episodes: 410\n",
      "0.013101874072991716\n",
      "episodes: 411\n",
      "0.013036528203437814\n",
      "episodes: 412\n",
      "0.012971508247767985\n",
      "episodes: 413\n",
      "0.012906812580479949\n",
      "episodes: 414\n",
      "0.012842439584178656\n",
      "episodes: 415\n",
      "0.012778387649535844\n",
      "episodes: 416\n",
      "0.012714655175249813\n",
      "episodes: 417\n",
      "0.012651240568005385\n",
      "episodes: 418\n",
      "0.012588142242434076\n",
      "episodes: 419\n",
      "0.012525358621074461\n",
      "episodes: 420\n",
      "0.012462888134332736\n",
      "episodes: 421\n",
      "0.012400729220443479\n",
      "episodes: 422\n",
      "0.012338880325430604\n",
      "episodes: 423\n",
      "0.012277339903068516\n",
      "episodes: 424\n",
      "0.01221610641484345\n",
      "episodes: 425\n",
      "0.012155178329915011\n",
      "episodes: 426\n",
      "0.012094554125077903\n",
      "episodes: 427\n",
      "0.012034232284723848\n",
      "episodes: 428\n",
      "0.011974211300803693\n",
      "episodes: 429\n",
      "0.011914489672789717\n",
      "episodes: 430\n",
      "0.011855065907638107\n",
      "episodes: 431\n",
      "0.01179593851975164\n",
      "episodes: 432\n",
      "0.011737106030942539\n",
      "episodes: 433\n",
      "0.011678566970395519\n",
      "episodes: 434\n",
      "0.011620319874631017\n",
      "episodes: 435\n",
      "0.011562363287468609\n",
      "episodes: 436\n",
      "0.011504695759990594\n",
      "episodes: 437\n",
      "0.011447315850505782\n",
      "episodes: 438\n",
      "0.011390222124513447\n",
      "episodes: 439\n",
      "0.011333413154667465\n",
      "episodes: 440\n",
      "0.011276887520740634\n",
      "episodes: 441\n",
      "0.011220643809589158\n",
      "episodes: 442\n",
      "0.011164680615117332\n",
      "episodes: 443\n",
      "0.011108996538242377\n",
      "episodes: 444\n",
      "0.011053590186859473\n",
      "episodes: 445\n",
      "0.010998460175806949\n",
      "episodes: 446\n",
      "0.010943605126831657\n",
      "episodes: 447\n",
      "0.010889023668554515\n",
      "episodes: 448\n",
      "0.010834714436436224\n",
      "episodes: 449\n",
      "0.010780676072743153\n",
      "episodes: 450\n",
      "0.010726907226513394\n",
      "episodes: 451\n",
      "0.010673406553522991\n",
      "episodes: 452\n",
      "0.010620172716252334\n",
      "episodes: 453\n",
      "0.010567204383852719\n",
      "episodes: 454\n",
      "0.010514500232113075\n",
      "episodes: 455\n",
      "0.010462058943426864\n",
      "episodes: 456\n",
      "0.010409879206759138\n",
      "episodes: 457\n",
      "0.010357959717613763\n",
      "episodes: 458\n",
      "0.010306299178000806\n",
      "episodes: 459\n",
      "0.010254896296404086\n",
      "episodes: 460\n",
      "0.010203749787748887\n",
      "episodes: 461\n",
      "0.010152858373369825\n",
      "episodes: 462\n",
      "0.010102220780978893\n",
      "episodes: 463\n",
      "0.010051835744633643\n",
      "episodes: 464\n",
      "0.010001702004705543\n",
      "episodes: 465\n",
      "0.009951818307848482\n",
      "episodes: 466\n",
      "0.009902183406967443\n",
      "episodes: 467\n",
      "0.009852796061187316\n",
      "episodes: 468\n",
      "0.009803655035821887\n",
      "episodes: 469\n",
      "0.00975475910234296\n",
      "episodes: 470\n",
      "0.009706107038349654\n",
      "episodes: 471\n",
      "0.009657697627537832\n",
      "episodes: 472\n",
      "0.009609529659669705\n",
      "episodes: 473\n",
      "0.009561601930543565\n",
      "episodes: 474\n",
      "0.009513913241963691\n",
      "episodes: 475\n",
      "0.009466462401710382\n",
      "episodes: 476\n",
      "0.009419248223510162\n",
      "episodes: 477\n",
      "0.009372269527006115\n",
      "episodes: 478\n",
      "0.009325525137728382\n",
      "episodes: 479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009279013887064798\n",
      "episodes: 480\n",
      "0.009232734612231673\n",
      "episodes: 481\n",
      "0.009186686156244725\n",
      "episodes: 482\n",
      "0.009140867367890156\n",
      "episodes: 483\n",
      "0.009095277101695873\n",
      "episodes: 484\n",
      "0.009049914217902844\n",
      "episodes: 485\n",
      "0.009004777582436613\n",
      "episodes: 486\n",
      "0.008959866066878942\n",
      "episodes: 487\n",
      "0.008915178548439604\n",
      "episodes: 488\n",
      "0.008870713909928309\n",
      "episodes: 489\n",
      "0.008826471039726778\n",
      "episodes: 490\n",
      "0.008782448831760954\n",
      "episodes: 491\n",
      "0.008738646185473343\n",
      "episodes: 492\n",
      "0.008695062005795506\n",
      "episodes: 493\n",
      "0.008651695203120684\n",
      "episodes: 494\n",
      "0.00860854469327655\n",
      "episodes: 495\n",
      "0.00856560939749811\n",
      "episodes: 496\n",
      "0.00852288824240073\n",
      "episodes: 497\n",
      "0.008480380159953314\n",
      "episodes: 498\n",
      "0.008438084087451583\n",
      "episodes: 499\n",
      "---------- 10616 32\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 1\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "+++++++++++++++++ 2 +++++++++++++ 0\n"
     ]
    }
   ],
   "source": [
    "# We iterate over episodes\n",
    "for e in range(n_episodes):\n",
    "    # We initialize the first state and reshape it to fit \n",
    "    #  with the input layer of the DNN\n",
    "    current_state = env.reset()\n",
    "    current_state = np.array([current_state])\n",
    "    for step in range(max_iteration_ep):\n",
    "        total_steps = total_steps + 1\n",
    "        # the agent computes the action to perform\n",
    "        action = agent.compute_action(current_state)\n",
    "        # the envrionment runs the action and returns\n",
    "        # the next state, a reward and whether the agent is done\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.array([next_state])\n",
    "        \n",
    "        # We sotre each experience in the memory buffer\n",
    "        agent.store_episode(current_state, action, reward, next_state, done)\n",
    "        \n",
    "        # if the episode is ended, we leave the loop after\n",
    "        # updating the exploration probability\n",
    "        if done:\n",
    "            agent.update_exploration_probability()\n",
    "            break\n",
    "        current_state = next_state\n",
    "    # if the have at least batch_size experiences in the memory buffer\n",
    "    # than we tain our model\n",
    "    print(\"episodes: %d\" % e)\n",
    "print(\"----------\", total_steps, agent.batch_size)\n",
    "if total_steps >= agent.batch_size:\n",
    "    agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1109fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   2   3   4   5   6   7   8   9  10 10.0\n"
     ]
    }
   ],
   "source": [
    "from gym import wrappers\n",
    "def make_video():\n",
    "#     env_to_wrap = gym.make('CartPole-v1')\n",
    "#     env = wrappers.Monitor(env_to_wrap, 'videos', force = True)\n",
    "    rewards = 0\n",
    "    steps = 0\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    state = np.array([state])\n",
    "    while not done:\n",
    "        action = agent.compute_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        state = np.array([state])            \n",
    "        steps += 1\n",
    "        print(\"%3d \" % steps, end=\"\")\n",
    "        rewards += reward\n",
    "    print(rewards)\n",
    "    #env.close()\n",
    "    #env_to_wrap.close()\n",
    "make_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd119781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet\n",
      "  Downloading pyglet-2.0.4-py3-none-any.whl (831 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.0/831.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyglet\n",
      "Successfully installed pyglet-2.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c8afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
