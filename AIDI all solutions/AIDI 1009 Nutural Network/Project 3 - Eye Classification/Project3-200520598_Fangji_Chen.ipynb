{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage.transform import resize\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nfrom sklearn.utils import resample\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, f1_score, roc_auc_score, roc_curve\nfrom PIL import Image\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\nfrom tensorflow.keras import layers\n! pip install visualkeras\nimport visualkeras\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:20.28967Z","iopub.execute_input":"2022-08-08T21:00:20.290147Z","iopub.status.idle":"2022-08-08T21:00:31.399784Z","shell.execute_reply.started":"2022-08-08T21:00:20.290098Z","shell.execute_reply":"2022-08-08T21:00:31.398162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset & Perform EDA","metadata":{}},{"cell_type":"code","source":"dir = '/kaggle/input'\nlabel = []\npath = []\nfor dirname, _,filenames in os.walk(dir):\n    for filename in filenames:\n        label.append(os.path.split(dirname)[1])\n        path.append(os.path.join(dirname,filename))\n             \ndf = pd.DataFrame(columns=['Image','Label'])\ndf['Image']=path\ndf['Label']=label\n\ndf = shuffle(df)\ndf = df.reset_index(drop=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-08T21:00:31.402985Z","iopub.execute_input":"2022-08-08T21:00:31.403886Z","iopub.status.idle":"2022-08-08T21:00:33.946836Z","shell.execute_reply.started":"2022-08-08T21:00:31.40383Z","shell.execute_reply":"2022-08-08T21:00:33.945678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observing Dataset","metadata":{}},{"cell_type":"code","source":"# Total number of samples\nlen(df)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:33.948556Z","iopub.execute_input":"2022-08-08T21:00:33.949615Z","iopub.status.idle":"2022-08-08T21:00:33.957349Z","shell.execute_reply.started":"2022-08-08T21:00:33.949569Z","shell.execute_reply":"2022-08-08T21:00:33.956142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check first 5 rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:33.959883Z","iopub.execute_input":"2022-08-08T21:00:33.960267Z","iopub.status.idle":"2022-08-08T21:00:33.976032Z","shell.execute_reply.started":"2022-08-08T21:00:33.960234Z","shell.execute_reply":"2022-08-08T21:00:33.974959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check last 5 columns\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:33.978111Z","iopub.execute_input":"2022-08-08T21:00:33.979337Z","iopub.status.idle":"2022-08-08T21:00:33.992977Z","shell.execute_reply.started":"2022-08-08T21:00:33.979291Z","shell.execute_reply":"2022-08-08T21:00:33.991734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Column info\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:33.994804Z","iopub.execute_input":"2022-08-08T21:00:33.995347Z","iopub.status.idle":"2022-08-08T21:00:34.01021Z","shell.execute_reply.started":"2022-08-08T21:00:33.995313Z","shell.execute_reply":"2022-08-08T21:00:34.009097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check total count and frequency of each label\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.011692Z","iopub.execute_input":"2022-08-08T21:00:34.012271Z","iopub.status.idle":"2022-08-08T21:00:34.040278Z","shell.execute_reply.started":"2022-08-08T21:00:34.012235Z","shell.execute_reply":"2022-08-08T21:00:34.039293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are total of 11525 Images in the entire dataset, having 2 labels [maleeyes, femaleeyes]. Frequency of maleeyes is greater then frequency of female eyes.","metadata":{}},{"cell_type":"code","source":"# check for null values or missing labels\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.042205Z","iopub.execute_input":"2022-08-08T21:00:34.043497Z","iopub.status.idle":"2022-08-08T21:00:34.057429Z","shell.execute_reply.started":"2022-08-08T21:00:34.043446Z","shell.execute_reply":"2022-08-08T21:00:34.056045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No null entries present in dataset.","metadata":{}},{"cell_type":"code","source":"# check for duplicate entries\ndf.duplicated().any()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.058722Z","iopub.execute_input":"2022-08-08T21:00:34.05992Z","iopub.status.idle":"2022-08-08T21:00:34.080808Z","shell.execute_reply.started":"2022-08-08T21:00:34.059881Z","shell.execute_reply":"2022-08-08T21:00:34.079479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the samples in the dataset are unique","metadata":{}},{"cell_type":"code","source":"# Count number of samples for each category [Male, Female]\nvc = df['Label'].value_counts()\nprint(vc)\n\nplt.figure(figsize = (9, 5))\nsns.barplot(x = vc.index, y = vc)\nplt.title(\"Number of images for each category in the Training Dataset\", fontsize = 11)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.08608Z","iopub.execute_input":"2022-08-08T21:00:34.086868Z","iopub.status.idle":"2022-08-08T21:00:34.28819Z","shell.execute_reply.started":"2022-08-08T21:00:34.086819Z","shell.execute_reply":"2022-08-08T21:00:34.287041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset has 6323 images of male and 5202 images of female eyes","metadata":{}},{"cell_type":"markdown","source":"#### Balancing Dataset","metadata":{}},{"cell_type":"code","source":"# Using downsampling to balance the dataset, \n# as there is not a big difference in the total number of samples in both categories\n\n# Dividing majority and minority classes\ndf_major = df[df.Label=='maleeyes']\ndf_minor = df[df.Label=='femaleeyes']\n\ndf_major_sample = resample(df_major,\n               replace=False,  # Down sample without replacement\n               n_samples=5202,   # Number to match minority class\n               random_state=42)\n  \n# Combine both samples\ndf = pd.concat([df_major_sample, df_minor])\ndf = shuffle(df)\ndf = df.reset_index(drop=True)\n\n# Display count of data points in both class\nprint(df.Label.value_counts())\n\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.289526Z","iopub.execute_input":"2022-08-08T21:00:34.28987Z","iopub.status.idle":"2022-08-08T21:00:34.331999Z","shell.execute_reply.started":"2022-08-08T21:00:34.289838Z","shell.execute_reply":"2022-08-08T21:00:34.331134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the downsampling technique we removed extra samples from maleeyes, now both labels have 5202 samples having all unique values. ","metadata":{}},{"cell_type":"markdown","source":"### Observing the images","metadata":{}},{"cell_type":"markdown","source":"Here we can see that size of both images are not same, hence we will resize female images to 54x54","metadata":{}},{"cell_type":"code","source":"# Get index of male and female eye\nxx = df[df['Label'] == 'femaleeyes'].index[0] # index of female eye\nxy = df[df['Label'] == 'maleeyes'].index[0] # index of male eye","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.333964Z","iopub.execute_input":"2022-08-08T21:00:34.334465Z","iopub.status.idle":"2022-08-08T21:00:34.346712Z","shell.execute_reply.started":"2022-08-08T21:00:34.334421Z","shell.execute_reply":"2022-08-08T21:00:34.345432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize female eye\nfigure = plt.figure(figsize=(2,2))\nx = plt.imread(df[\"Image\"][xx])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(df[\"Label\"][xx])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:34.348335Z","iopub.execute_input":"2022-08-08T21:00:34.348888Z","iopub.status.idle":"2022-08-08T21:00:35.05587Z","shell.execute_reply.started":"2022-08-08T21:00:34.348852Z","shell.execute_reply":"2022-08-08T21:00:35.055007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize male eye\nfigure = plt.figure(figsize=(2, 2))\nx = plt.imread(df[\"Image\"][xy])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(df[\"Label\"][xy])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:35.057244Z","iopub.execute_input":"2022-08-08T21:00:35.058155Z","iopub.status.idle":"2022-08-08T21:00:35.251444Z","shell.execute_reply.started":"2022-08-08T21:00:35.058093Z","shell.execute_reply":"2022-08-08T21:00:35.250224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot more random images from dataset\nfig, axes = plt.subplots(nrows = 5,\n                        ncols = 5,\n                        figsize = (7, 7),\n                        subplot_kw = {\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df[\"Image\"][i]))\n    ax.set_title(df[\"Label\"][i])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:35.253405Z","iopub.execute_input":"2022-08-08T21:00:35.254196Z","iopub.status.idle":"2022-08-08T21:00:36.481697Z","shell.execute_reply.started":"2022-08-08T21:00:35.254146Z","shell.execute_reply":"2022-08-08T21:00:36.480676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking image size\nfemale_eye_size = plt.imread(df[\"Image\"][xx])\nprint(female_eye_size.shape, '==>',  df['Label'][xx])\n\nmale_eye_size = plt.imread(df[\"Image\"][xy])\nprint(male_eye_size.shape, '==>',  df['Label'][xy])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:36.483256Z","iopub.execute_input":"2022-08-08T21:00:36.483845Z","iopub.status.idle":"2022-08-08T21:00:36.492637Z","shell.execute_reply.started":"2022-08-08T21:00:36.483808Z","shell.execute_reply":"2022-08-08T21:00:36.49162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here all the images have varying sizes, we should resize all the images to equal size for better classification.","metadata":{}},{"cell_type":"code","source":"# Check how many different sized images are there\n\nsize_list=set() # empty set for checking total different sizes of images\n\nfor x in range(len(df['Image'])):\n    size_list.add(plt.imread(df[\"Image\"][x]).shape)\n\nprint(len(size_list))\nprint('Smallest size :', list(sorted(size_list))[0])\nprint('Largest size :', list(sorted(size_list))[-1])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:36.493957Z","iopub.execute_input":"2022-08-08T21:00:36.494491Z","iopub.status.idle":"2022-08-08T21:00:50.939607Z","shell.execute_reply.started":"2022-08-08T21:00:36.494458Z","shell.execute_reply":"2022-08-08T21:00:50.938115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains images with 65 different sizes, ranging from 41x41 to 117x117.\nWe will now resize them to 64x64 size.","metadata":{}},{"cell_type":"code","source":"# Convert image path to array of image using cv2\nsize = (64,64)\ndf1 = df.copy()\n\nsize_list = set()\nfor i in range(len(df)):\n    image=cv2.imread(df['Image'][i])\n    image=cv2.resize(image,size)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    size_list.add(image.shape)\n    df1['Image'][i] = image.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:00:50.94139Z","iopub.execute_input":"2022-08-08T21:00:50.941923Z","iopub.status.idle":"2022-08-08T21:01:06.35721Z","shell.execute_reply.started":"2022-08-08T21:00:50.941871Z","shell.execute_reply":"2022-08-08T21:01:06.356231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check shape after resizing\nsize_list","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:01:06.361148Z","iopub.execute_input":"2022-08-08T21:01:06.361555Z","iopub.status.idle":"2022-08-08T21:01:06.369296Z","shell.execute_reply.started":"2022-08-08T21:01:06.361518Z","shell.execute_reply":"2022-08-08T21:01:06.36836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now all the images have same size ==> 64x64, and falttened to perform KNN","metadata":{}},{"cell_type":"code","source":"# Finally let's see some random images again\n\nfig, axes = plt.subplots(nrows = 5,\n                        ncols = 5,\n                        figsize = (7, 7),\n                        subplot_kw = {\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(df1.Image[i].reshape(64,64,3))\n    ax.set_title(df1[\"Label\"][i])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:01:06.370822Z","iopub.execute_input":"2022-08-08T21:01:06.371561Z","iopub.status.idle":"2022-08-08T21:01:07.583759Z","shell.execute_reply.started":"2022-08-08T21:01:06.371506Z","shell.execute_reply":"2022-08-08T21:01:07.582463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to numeric values\n\nLE = LabelEncoder()\n\ndf1['Label'] = np.asarray(LE.fit_transform(df1[\"Label\"]))\n\ndisplay(df1.head())","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:01:07.585417Z","iopub.execute_input":"2022-08-08T21:01:07.586088Z","iopub.status.idle":"2022-08-08T21:01:07.609608Z","shell.execute_reply.started":"2022-08-08T21:01:07.586049Z","shell.execute_reply":"2022-08-08T21:01:07.608697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"code","source":"# Function to reset the index and reshape the array \ndef cleaned(X):\n    for i in range(len(X)):\n        X[i] = np.vstack(X[i].reset_index(drop=True))\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:01:07.610904Z","iopub.execute_input":"2022-08-08T21:01:07.611451Z","iopub.status.idle":"2022-08-08T21:01:07.617163Z","shell.execute_reply.started":"2022-08-08T21:01:07.611417Z","shell.execute_reply":"2022-08-08T21:01:07.616024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into train and test\nX_train1, X_test1,y_train1, y_test1 = train_test_split(df1.Image, df1.Label, test_size = 0.2, random_state = 7)\n\nX_train1, X_test1,y_train1, y_test1 = cleaned([X_train1, X_test1,y_train1, y_test1])\n\nprint(X_train1.shape, X_test1.shape)\nprint(y_train1.shape, y_test1.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:22:43.142111Z","iopub.execute_input":"2022-08-09T00:22:43.142542Z","iopub.status.idle":"2022-08-09T00:22:43.431763Z","shell.execute_reply.started":"2022-08-09T00:22:43.142504Z","shell.execute_reply":"2022-08-09T00:22:43.430372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying KNN multiple times to find best value of K\n\nerror_rate = []\nacc = []\n\nfor i in range(1,5):\n \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train1,y_train1)\n    pred_i = knn.predict(X_test1)\n    error_rate.append(np.mean(pred_i != y_test))","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:25:16.29555Z","iopub.execute_input":"2022-08-09T00:25:16.296407Z","iopub.status.idle":"2022-08-09T00:25:46.966239Z","shell.execute_reply.started":"2022-08-09T00:25:16.296358Z","shell.execute_reply":"2022-08-09T00:25:46.964642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Elbow plot to see optimum value of K\nplt.figure(figsize=(10,6))\nplt.plot(range(1,5),error_rate,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:25:46.968401Z","iopub.execute_input":"2022-08-09T00:25:46.968803Z","iopub.status.idle":"2022-08-09T00:25:47.261344Z","shell.execute_reply.started":"2022-08-09T00:25:46.968764Z","shell.execute_reply":"2022-08-09T00:25:47.260111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NOW WITH K=16\nKNN = KNeighborsClassifier(n_neighbors=20)\nKNN.fit(X_train1,y_train1)\nknn_pred = KNN.predict(X_test1)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:25:47.262759Z","iopub.execute_input":"2022-08-09T00:25:47.264958Z","iopub.status.idle":"2022-08-09T00:25:54.780979Z","shell.execute_reply.started":"2022-08-09T00:25:47.264914Z","shell.execute_reply":"2022-08-09T00:25:54.779529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print accuracy\n%time\n# 84.1 - Best Accuracy found \nprint('KNN Accuracy: %.3f' % accuracy_score(y_test1,knn_pred))","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:25:54.784317Z","iopub.execute_input":"2022-08-09T00:25:54.784858Z","iopub.status.idle":"2022-08-09T00:25:54.796757Z","shell.execute_reply.started":"2022-08-09T00:25:54.784802Z","shell.execute_reply":"2022-08-09T00:25:54.795513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nknn_cm = confusion_matrix(y_test1,knn_pred)\nplt.figure(figsize=(9,9))\nsns.heatmap(knn_cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap=\"Pastel1\")\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nall_sample_title = 'Accuracy Score: {0}'.format(accuracy_score(y_test1,knn_pred))\nplt.title(all_sample_title,size=15)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:25:54.798797Z","iopub.execute_input":"2022-08-09T00:25:54.799514Z","iopub.status.idle":"2022-08-09T00:25:55.120844Z","shell.execute_reply.started":"2022-08-09T00:25:54.799474Z","shell.execute_reply":"2022-08-09T00:25:55.119398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nKNN_Classification_Report = classification_report(y_test1,knn_pred)\nprint(KNN_Classification_Report)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:25:55.122327Z","iopub.execute_input":"2022-08-09T00:25:55.122729Z","iopub.status.idle":"2022-08-09T00:25:55.140637Z","shell.execute_reply.started":"2022-08-09T00:25:55.122692Z","shell.execute_reply":"2022-08-09T00:25:55.139229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the confusion matrix that our KNN classifier has an accuracy of approx 83.7%, where from 2081 samples, the algorithm correctly identified 840 samples as True Positive, 901 as True Negatives, 193 as False Positive and 147 as False Negatives.\n\nWith an average precision of 84%, recall of 84% and f1-score and accuracy of about 0.84. ","metadata":{}},{"cell_type":"markdown","source":"# MLP\n","metadata":{}},{"cell_type":"markdown","source":"#### Train Val Test Split","metadata":{}},{"cell_type":"code","source":"# Deviding df to Train Test and Validation set\n\nX_train2, X_val2, y_train2, y_val2 = train_test_split(df1.Image, df1.Label, test_size = 0.4, random_state = 7)\nX_val2, X_test2,y_val2, y_test2 = train_test_split(X_val2, y_val2, test_size = 0.5, random_state = 7)\n\nx_train2, x_val2, x_test2, y_train2, y_val2, y_test2 = cleaned([X_train2, X_val2, X_test2, y_train2, y_val2, y_test2])\n\nprint(\"X_Train: \", x_train2.shape) \nprint(\"X_Val: \", x_val2.shape) \nprint(\"X_Test: \", x_test2.shape) \nprint(\"y_Train: \", y_train2.shape) \nprint(\"y_Val: \", y_val2.shape) \nprint(\"y_test: \", y_test2.shape) ","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:28:52.405023Z","iopub.execute_input":"2022-08-09T00:28:52.405536Z","iopub.status.idle":"2022-08-09T00:28:52.520958Z","shell.execute_reply.started":"2022-08-09T00:28:52.405496Z","shell.execute_reply":"2022-08-09T00:28:52.519694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Architechture","metadata":{}},{"cell_type":"code","source":"# Model architechture\nMLP = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(1024, activation=tf.nn.leaky_relu), \n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation=tf.nn.leaky_relu), \n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid') \n])","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:28:53.186234Z","iopub.execute_input":"2022-08-09T00:28:53.186646Z","iopub.status.idle":"2022-08-09T00:28:53.205395Z","shell.execute_reply.started":"2022-08-09T00:28:53.186613Z","shell.execute_reply":"2022-08-09T00:28:53.203966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Optimize","metadata":{}},{"cell_type":"code","source":"male = len(y_train2[y_train2>0])\nfemale = len(y_train2) - male\ntotal = len(y_train2)\nweight_for_male = total / (2 * male) \nweight_for_female = total / (2 * female)\nclass_weight = {0: weight_for_female, 1: weight_for_male}\nprint(class_weight)\n\n# Optimizer\nadam_optimizer = tf.keras.optimizers.Adam()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:36:57.41329Z","iopub.execute_input":"2022-08-08T21:36:57.415768Z","iopub.status.idle":"2022-08-08T21:36:57.429104Z","shell.execute_reply.started":"2022-08-08T21:36:57.415654Z","shell.execute_reply":"2022-08-08T21:36:57.427583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Compile","metadata":{}},{"cell_type":"code","source":"\nMLP.compile(\n    optimizer=adam_optimizer,\n    loss='binary_crossentropy',\n    metrics=[\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n    ]\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:36:57.899346Z","iopub.execute_input":"2022-08-08T21:36:57.900741Z","iopub.status.idle":"2022-08-08T21:36:57.955998Z","shell.execute_reply.started":"2022-08-08T21:36:57.900672Z","shell.execute_reply":"2022-08-08T21:36:57.953912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training model","metadata":{}},{"cell_type":"code","source":"# Training \nscaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train2)\nmlp_history = MLP.fit(x_train_scaled, \n          y_train2,\n          class_weight=class_weight,\n          batch_size=64,\n          validation_data=(x_val2,y_val2),\n#           callbacks=[save_best_callback],\n          epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:36:58.088344Z","iopub.execute_input":"2022-08-08T21:36:58.088931Z","iopub.status.idle":"2022-08-08T21:39:46.38798Z","shell.execute_reply.started":"2022-08-08T21:36:58.088885Z","shell.execute_reply":"2022-08-08T21:39:46.386834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print()\nvisualkeras.layered_view(MLP, scale_xy=100, scale_z=100, max_z=200, legend = True, spacing = 20)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:37:36.426526Z","iopub.execute_input":"2022-08-08T22:37:36.427028Z","iopub.status.idle":"2022-08-08T22:37:36.444195Z","shell.execute_reply.started":"2022-08-08T22:37:36.426991Z","shell.execute_reply":"2022-08-08T22:37:36.443312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate & Predict","metadata":{}},{"cell_type":"code","source":"# Evaluate model\nx_test_scaled = scaler.fit_transform(x_test2)\nscore = MLP.evaluate(x_test_scaled, y_test2, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:46.391533Z","iopub.execute_input":"2022-08-08T21:39:46.392318Z","iopub.status.idle":"2022-08-08T21:39:50.388496Z","shell.execute_reply.started":"2022-08-08T21:39:46.39226Z","shell.execute_reply":"2022-08-08T21:39:50.38668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predictions \ny_pred2 = MLP.predict(x_test_scaled)\ny_pred2 = np.where(y_pred2 > 0.5, 1, 0)\ny_pred2","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:50.391189Z","iopub.execute_input":"2022-08-08T21:39:50.391672Z","iopub.status.idle":"2022-08-08T21:39:51.703688Z","shell.execute_reply.started":"2022-08-08T21:39:50.391635Z","shell.execute_reply":"2022-08-08T21:39:51.702679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(mlp_history.history['accuracy'])\nplt.plot(mlp_history.history['val_accuracy'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.title('model accuracy')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:51.706673Z","iopub.execute_input":"2022-08-08T21:39:51.707334Z","iopub.status.idle":"2022-08-08T21:39:51.970797Z","shell.execute_reply.started":"2022-08-08T21:39:51.707293Z","shell.execute_reply":"2022-08-08T21:39:51.969142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(mlp_history.history['loss'])\nplt.plot(mlp_history.history['val_loss'])\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.title('model loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:51.972137Z","iopub.execute_input":"2022-08-08T21:39:51.972603Z","iopub.status.idle":"2022-08-08T21:39:52.229036Z","shell.execute_reply.started":"2022-08-08T21:39:51.972566Z","shell.execute_reply":"2022-08-08T21:39:52.22806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nMLP_Classification_Report = classification_report(y_test2,y_pred2)\nprint(MLP_Classification_Report)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:52.230492Z","iopub.execute_input":"2022-08-08T21:39:52.231246Z","iopub.status.idle":"2022-08-08T21:39:52.247809Z","shell.execute_reply.started":"2022-08-08T21:39:52.231178Z","shell.execute_reply":"2022-08-08T21:39:52.245621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"markdown","source":"#### Helper Functions","metadata":{}},{"cell_type":"code","source":"# Helper function\ndef to_tensor(_list):\n    LIST = []\n    for i in range(len(_list)):\n        LIST.append(tf.convert_to_tensor(_list[i]))\n    return LIST","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:52.250426Z","iopub.execute_input":"2022-08-08T21:39:52.251308Z","iopub.status.idle":"2022-08-08T21:39:52.257611Z","shell.execute_reply.started":"2022-08-08T21:39:52.251263Z","shell.execute_reply":"2022-08-08T21:39:52.256352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function\n# Function to reset the index and reshape the array \ndef cleaned2(X):\n    for i in range(len(X)):\n        X[i] = np.stack(X[i].reset_index(drop=True))\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:52.259332Z","iopub.execute_input":"2022-08-08T21:39:52.260782Z","iopub.status.idle":"2022-08-08T21:39:52.273891Z","shell.execute_reply.started":"2022-08-08T21:39:52.260733Z","shell.execute_reply":"2022-08-08T21:39:52.272644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert image path to array of image using cv2\nsize = (64,64)\ndf2 = df.copy()\n\nfor i in range(len(df)):\n    image=cv2.imread(df['Image'][i])\n    image=cv2.resize(image,size)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    df2['Image'][i] = image\n    \n# Convert labels to numeric values\n\nLE = LabelEncoder()\n\ndf2['Label'] = np.asarray(LE.fit_transform(df2[\"Label\"]))\n\ndisplay(df2.head())","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:39:52.275591Z","iopub.execute_input":"2022-08-08T21:39:52.276286Z","iopub.status.idle":"2022-08-08T21:40:40.558881Z","shell.execute_reply.started":"2022-08-08T21:39:52.276246Z","shell.execute_reply":"2022-08-08T21:40:40.556947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.Image[1].shape","metadata":{"execution":{"iopub.status.busy":"2022-08-08T21:40:40.563812Z","iopub.execute_input":"2022-08-08T21:40:40.564515Z","iopub.status.idle":"2022-08-08T21:40:40.574942Z","shell.execute_reply.started":"2022-08-08T21:40:40.564459Z","shell.execute_reply":"2022-08-08T21:40:40.573406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deviding df to Train Test and Validation set\n\nx_train3, x_val3, y_train3, y_val3 = train_test_split(df2.Image, df2.Label, test_size = 0.4, random_state = 7)\nx_val3, x_test3, y_val3, y_test3 = train_test_split(x_val3, y_val3, test_size = 0.5, random_state = 7)\n\nx_train3, x_val3, x_test3, y_train3, y_val3, y_test3 = cleaned2([x_train3, x_val3, x_test3, y_train3, y_val3, y_test3])\nx_train3, x_val3, x_test3, y_train3, y_val3, y_test3 = to_tensor([x_train3, x_val3, x_test3, y_train3, y_val3, y_test3])\n\nprint(\"X Train: \", x_train3.shape) \nprint(\"X Val: \", x_val3.shape) \nprint(\"X Test: \", x_test3.shape) \nprint(\"y Train: \", y_train3.shape) \nprint(\"y Val: \", y_val3.shape) \nprint(\"y test: \", y_test3.shape) ","metadata":{"execution":{"iopub.status.busy":"2022-08-09T00:33:50.702863Z","iopub.execute_input":"2022-08-09T00:33:50.704244Z","iopub.status.idle":"2022-08-09T00:33:51.099621Z","shell.execute_reply.started":"2022-08-09T00:33:50.704193Z","shell.execute_reply":"2022-08-09T00:33:51.09862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Architechture","metadata":{}},{"cell_type":"code","source":"# Alex-Net Architechture\n\nCNN=keras.models.Sequential([\n    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(64,64,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3)),\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1024,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1024,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1,activation='sigmoid')  \n])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:38:19.778164Z","iopub.execute_input":"2022-08-08T22:38:19.778601Z","iopub.status.idle":"2022-08-08T22:38:19.980227Z","shell.execute_reply.started":"2022-08-08T22:38:19.778563Z","shell.execute_reply":"2022-08-08T22:38:19.978973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print()\nvisualkeras.layered_view(CNN, scale_xy=14, scale_z=14, max_z=45, legend = True, spacing = 20)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:38:20.985477Z","iopub.execute_input":"2022-08-08T22:38:20.985914Z","iopub.status.idle":"2022-08-08T22:38:21.038314Z","shell.execute_reply.started":"2022-08-08T22:38:20.985874Z","shell.execute_reply":"2022-08-08T22:38:21.037233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:38:22.627164Z","iopub.execute_input":"2022-08-08T22:38:22.627634Z","iopub.status.idle":"2022-08-08T22:38:22.64086Z","shell.execute_reply.started":"2022-08-08T22:38:22.627594Z","shell.execute_reply":"2022-08-08T22:38:22.639379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_history=CNN.fit(x_train3, y_train3, validation_data=(x_val3, y_val3),\n            epochs=20,\n#             callbacks=[early_stop,reduce_lr]\n           )","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:38:24.011939Z","iopub.execute_input":"2022-08-08T22:38:24.012841Z","iopub.status.idle":"2022-08-08T22:46:27.843603Z","shell.execute_reply.started":"2022-08-08T22:38:24.012793Z","shell.execute_reply":"2022-08-08T22:46:27.842476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plot Training and Validation Loss ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.plot(cnn_history.history['loss'])\nplt.plot(cnn_history.history['val_loss'])\nplt.title('Loss curve',fontdict={'size':20})\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:15:32.581013Z","iopub.execute_input":"2022-08-08T22:15:32.581468Z","iopub.status.idle":"2022-08-08T22:15:32.805332Z","shell.execute_reply.started":"2022-08-08T22:15:32.581424Z","shell.execute_reply":"2022-08-08T22:15:32.803978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.plot(cnn_history.history['accuracy'])\nplt.plot(cnn_history.history['val_accuracy'])\nplt.title('Accuracy curve',fontdict={'size':20})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:15:34.646563Z","iopub.execute_input":"2022-08-08T22:15:34.646993Z","iopub.status.idle":"2022-08-08T22:15:34.858691Z","shell.execute_reply.started":"2022-08-08T22:15:34.646955Z","shell.execute_reply":"2022-08-08T22:15:34.857393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_CNN = CNN.predict(x_test)\ny_pred_CNN = np.round(y_pred_CNN)\n\nrecall_CNN = recall_score(y_test, y_pred_CNN)\nprecision_CNN = precision_score(y_test, y_pred_CNN)\nf1_CNN = f1_score(y_test, y_pred_CNN)\nroc_CNN = roc_auc_score(y_test, y_pred_CNN)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:15:36.258863Z","iopub.execute_input":"2022-08-08T22:15:36.259318Z","iopub.status.idle":"2022-08-08T22:15:38.534419Z","shell.execute_reply.started":"2022-08-08T22:15:36.259283Z","shell.execute_reply":"2022-08-08T22:15:38.533292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nCNN_Classification_Report = classification_report(y_test, y_pred_CNN)\nprint(CNN_Classification_Report)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T22:15:38.536091Z","iopub.execute_input":"2022-08-08T22:15:38.538532Z","iopub.status.idle":"2022-08-08T22:15:38.553014Z","shell.execute_reply.started":"2022-08-08T22:15:38.538482Z","shell.execute_reply":"2022-08-08T22:15:38.552079Z"},"trusted":true},"execution_count":null,"outputs":[]}]}