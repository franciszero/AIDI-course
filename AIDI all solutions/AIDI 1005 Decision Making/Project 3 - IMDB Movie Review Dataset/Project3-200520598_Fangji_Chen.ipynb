{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e599f1",
   "metadata": {},
   "source": [
    "# Project 3 â€“ IMDB MOVIE REVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89602024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:37:01.538115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import category_encoders as ce\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from xgboost import *\n",
    "from scipy.stats import normaltest, linregress\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.datasets import load_digits, make_hastie_10_2, load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import distance_metric, type_metric\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "import unicodedata\n",
    "import warnings\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression, mutual_info_classif, SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from nltk import corpus, RegexpTokenizer, word_tokenize, download, ToktokTokenizer\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk import corpus, RegexpTokenizer, word_tokenize, download, ToktokTokenizer\n",
    "import spacy.cli\n",
    "\n",
    "# %matplotlib\n",
    "# %matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 5000)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd59126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/francis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessing:\n",
    "    def __init__(self):\n",
    "        download('punkt')\n",
    "        self.stopword_list = corpus.stopwords.words('english')\n",
    "        additional_stopwords = ['also', 'fd', 'nan', 'oh', 'ok', 'ms', 'mr', 'aa', 'yet', 'become', 'fd', 'ol', 'em', 'hey',\n",
    "                               'wb', 'ct']\n",
    "        self.stopword_list.append(additional_stopwords)\n",
    "        self.stopword_list.remove('not')\n",
    "\n",
    "        # see: https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/nlp%20proven%20approach/contractions.py\n",
    "        self.CONTRACTION_MAP = {\n",
    "            \"ain't\": \"is not\",\n",
    "            \"aren't\": \"are not\",\n",
    "            \"can't\": \"cannot\",\n",
    "            \"can't've\": \"cannot have\",\n",
    "            \"'cause\": \"because\",\n",
    "            \"could've\": \"could have\",\n",
    "            \"couldn't\": \"could not\",\n",
    "            \"couldn't've\": \"could not have\",\n",
    "            \"didn't\": \"did not\",\n",
    "            \"doesn't\": \"does not\",\n",
    "            \"don't\": \"do not\",\n",
    "            \"hadn't\": \"had not\",\n",
    "            \"hadn't've\": \"had not have\",\n",
    "            \"hasn't\": \"has not\",\n",
    "            \"haven't\": \"have not\",\n",
    "            \"he'd\": \"he would\",\n",
    "            \"he'd've\": \"he would have\",\n",
    "            \"he'll\": \"he will\",\n",
    "            \"he'll've\": \"he he will have\",\n",
    "            \"he's\": \"he is\",\n",
    "            \"how'd\": \"how did\",\n",
    "            \"how'd'y\": \"how do you\",\n",
    "            \"how'll\": \"how will\",\n",
    "            \"how's\": \"how is\",\n",
    "            \"I'd\": \"I would\",\n",
    "            \"I'd've\": \"I would have\",\n",
    "            \"I'll\": \"I will\",\n",
    "            \"I'll've\": \"I will have\",\n",
    "            \"I'm\": \"I am\",\n",
    "            \"I've\": \"I have\",\n",
    "            \"i'd\": \"i would\",\n",
    "            \"i'd've\": \"i would have\",\n",
    "            \"i'll\": \"i will\",\n",
    "            \"i'll've\": \"i will have\",\n",
    "            \"i'm\": \"i am\",\n",
    "            \"i've\": \"i have\",\n",
    "            \"isn't\": \"is not\",\n",
    "            \"it'd\": \"it would\",\n",
    "            \"it'd've\": \"it would have\",\n",
    "            \"it'll\": \"it will\",\n",
    "            \"it'll've\": \"it will have\",\n",
    "            \"it's\": \"it is\",\n",
    "            \"let's\": \"let us\",\n",
    "            \"ma'am\": \"madam\",\n",
    "            \"mayn't\": \"may not\",\n",
    "            \"might've\": \"might have\",\n",
    "            \"mightn't\": \"might not\",\n",
    "            \"mightn't've\": \"might not have\",\n",
    "            \"must've\": \"must have\",\n",
    "            \"mustn't\": \"must not\",\n",
    "            \"mustn't've\": \"must not have\",\n",
    "            \"needn't\": \"need not\",\n",
    "            \"needn't've\": \"need not have\",\n",
    "            \"o'clock\": \"of the clock\",\n",
    "            \"oughtn't\": \"ought not\",\n",
    "            \"oughtn't've\": \"ought not have\",\n",
    "            \"shan't\": \"shall not\",\n",
    "            \"sha'n't\": \"shall not\",\n",
    "            \"shan't've\": \"shall not have\",\n",
    "            \"she'd\": \"she would\",\n",
    "            \"she'd've\": \"she would have\",\n",
    "            \"she'll\": \"she will\",\n",
    "            \"she'll've\": \"she will have\",\n",
    "            \"she's\": \"she is\",\n",
    "            \"should've\": \"should have\",\n",
    "            \"shouldn't\": \"should not\",\n",
    "            \"shouldn't've\": \"should not have\",\n",
    "            \"so've\": \"so have\",\n",
    "            \"so's\": \"so as\",\n",
    "            \"that'd\": \"that would\",\n",
    "            \"that'd've\": \"that would have\",\n",
    "            \"that's\": \"that is\",\n",
    "            \"there'd\": \"there would\",\n",
    "            \"there'd've\": \"there would have\",\n",
    "            \"there's\": \"there is\",\n",
    "            \"they'd\": \"they would\",\n",
    "            \"they'd've\": \"they would have\",\n",
    "            \"they'll\": \"they will\",\n",
    "            \"they'll've\": \"they will have\",\n",
    "            \"they're\": \"they are\",\n",
    "            \"they've\": \"they have\",\n",
    "            \"to've\": \"to have\",\n",
    "            \"wasn't\": \"was not\",\n",
    "            \"we'd\": \"we would\",\n",
    "            \"we'd've\": \"we would have\",\n",
    "            \"we'll\": \"we will\",\n",
    "            \"we'll've\": \"we will have\",\n",
    "            \"we're\": \"we are\",\n",
    "            \"we've\": \"we have\",\n",
    "            \"weren't\": \"were not\",\n",
    "            \"what'll\": \"what will\",\n",
    "            \"what'll've\": \"what will have\",\n",
    "            \"what're\": \"what are\",\n",
    "            \"what's\": \"what is\",\n",
    "            \"what've\": \"what have\",\n",
    "            \"when's\": \"when is\",\n",
    "            \"when've\": \"when have\",\n",
    "            \"where'd\": \"where did\",\n",
    "            \"where's\": \"where is\",\n",
    "            \"where've\": \"where have\",\n",
    "            \"who'll\": \"who will\",\n",
    "            \"who'll've\": \"who will have\",\n",
    "            \"who's\": \"who is\",\n",
    "            \"who've\": \"who have\",\n",
    "            \"why's\": \"why is\",\n",
    "            \"why've\": \"why have\",\n",
    "            \"will've\": \"will have\",\n",
    "            \"won't\": \"will not\",\n",
    "            \"won't've\": \"will not have\",\n",
    "            \"would've\": \"would have\",\n",
    "            \"wouldn't\": \"would not\",\n",
    "            \"wouldn't've\": \"would not have\",\n",
    "            \"y'all\": \"you all\",\n",
    "            \"y'all'd\": \"you all would\",\n",
    "            \"y'all'd've\": \"you all would have\",\n",
    "            \"y'all're\": \"you all are\",\n",
    "            \"y'all've\": \"you all have\",\n",
    "            \"you'd\": \"you would\",\n",
    "            \"you'd've\": \"you would have\",\n",
    "            \"you'll\": \"you will\",\n",
    "            \"you'll've\": \"you will have\",\n",
    "            \"you're\": \"you are\",\n",
    "            \"you've\": \"you have\"\n",
    "        }\n",
    "\n",
    "        self.doc = pd.read_excel(\"IMDB_dataset.xlsx\")\n",
    "        self.test = \"It's Eighty-seven NLP jobs in 1950 ~ 1960s, yet. ,  Onward!\"\n",
    "\n",
    "    def expand_match(self, contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = self.CONTRACTION_MAP.get(match) \\\n",
    "            if self.CONTRACTION_MAP.get(match) \\\n",
    "            else self.CONTRACTION_MAP.get(match.lower())\n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "\n",
    "    def process_contraction(self, line):\n",
    "        contractions_pattern = re.compile('({})'.format('|'.join(self.CONTRACTION_MAP.keys())), flags=re.IGNORECASE | re.DOTALL)\n",
    "        return contractions_pattern.sub(self.expand_match, line)\n",
    "\n",
    "    def remove_punctuations(self, line):\n",
    "        # remove punctuations\n",
    "        punctuation = '\\[\\]\\.!,;:?\"\\'\\(\\)\\*-[0-9]\\{1-3\\}'\n",
    "        return re.sub(r'[{}]+'.format(punctuation), ' ', line)\n",
    "\n",
    "    def process_ToktokTokenizer(self, line):\n",
    "        tokenizer = ToktokTokenizer()\n",
    "        tokens = tokenizer.tokenize(line)\n",
    "        tokens = [token.strip() for token in tokens]\n",
    "        return np.array(tokens)\n",
    "\n",
    "    def process_ToktokTokenizer(self, line):\n",
    "        tokenizer = ToktokTokenizer()\n",
    "        tokens = tokenizer.tokenize(line)\n",
    "        tokens = [token.strip() for token in tokens]\n",
    "        return np.array(tokens)\n",
    "\n",
    "    def remove_stopwords(self, tokens):\n",
    "        tks = [token for token in tokens if token not in self.stopword_list and len(token)!=1]\n",
    "        sws = [token for token in tokens if token in self.stopword_list]            \n",
    "        return str(tks)  # , np.array(sws)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    foo = TextPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135d6e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I thought this was a wonderful way to spend ti...  positive\n",
       "1  Probably my all-time favorite movie, a story o...  positive\n",
       "2  I sure would like to see a resurrection of a u...  positive\n",
       "3  This show was an amazing, fresh & innovative i...  negative\n",
       "4  Encouraged by the positive comments about this...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98134ae0",
   "metadata": {},
   "source": [
    "### There are 25000 rows of text data in this document, the label are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e51036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1774d40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "negative    12500\n",
       "positive    12500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.doc.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea12c9",
   "metadata": {},
   "source": [
    "### Based on the description, I split the dataset into training set, and test set, equaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89e0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        This was a terrible film. There was no story l...\n",
       "1        The story line has been rehashed a number of t...\n",
       "2        LCDR Tom Dodge, despite having a reputation am...\n",
       "3        I suppose for 1961 this film was supposed to b...\n",
       "4        I strongly disagree with \"ctomvelu\" regarding ...\n",
       "                               ...                        \n",
       "12495    The Emperor's New Groove was a great twist for...\n",
       "12496    Ashley Judd, in an early role and I think her ...\n",
       "12497    As a huge fan or the Cracker series, I have be...\n",
       "12498    Another Day - this movie requires you to watch...\n",
       "12499    Maybe I saw a cleaned up version, but other th...\n",
       "Name: review, Length: 12500, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = foo.doc['review']\n",
    "y = foo.doc['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac46b3",
   "metadata": {},
   "source": [
    "##### Training set are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0999d76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index\n",
       "sentiment       \n",
       "negative    6250\n",
       "positive    6250"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train label balance\n",
    "pd.DataFrame(y_train).reset_index().groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9619",
   "metadata": {},
   "source": [
    "##### Test set are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff68b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index\n",
       "sentiment       \n",
       "negative    6250\n",
       "positive    6250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test label balance\n",
    "pd.DataFrame(y_test).reset_index().groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd0bbd",
   "metadata": {},
   "source": [
    "### Applying preprocessing steps on 5000 samples for tuning all the processes that needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8404ebbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['adaptation', 'dirk', 'wittenborn', 'book', '...\n",
       "1       ['crappy', 'movie', 'idea', 'get', 'shelf', 'm...\n",
       "2       ['want', 'like', 'movie', 'little', 'like', 's...\n",
       "3       ['surprising', 'production', 'like', 'gets', '...\n",
       "4       ['convict', 'serve', 'time', 'come', 'forward'...\n",
       "                              ...                        \n",
       "2495    ['one', 'time', 'favorite', 'simple', 'sweet',...\n",
       "2496    ['star', 'trek', 'motion', 'picture', 'mostly'...\n",
       "2497    ['movie', 'try', 'capture', 'essence', 'surrea...\n",
       "2498    ['work', 'video', 'store', 'get', 'see', 'one'...\n",
       "2499    ['child', 'watch', 'show', 'everyday', 'great'...\n",
       "Name: review, Length: 2500, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = foo.doc.head(5000)['review']\n",
    "y = foo.doc.head(5000)['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "X_train = X_train.apply(lambda l: BeautifulSoup(l, \"html.parser\").get_text())\n",
    "X_train = X_train.apply(lambda l: unicodedata.normalize('NFKD', l))\n",
    "X_train = X_train.apply(lambda l: re.sub(r'[^a-zA-Z0-9\\s]', '', l))\n",
    "X_train = X_train.apply(lambda l: re.sub(r'[0-9]+', '', l))\n",
    "X_train = X_train.apply(lambda l: re.sub('\\[[^]]*\\]', '', l))\n",
    "X_train = X_train.apply(lambda l: l.lower())\n",
    "# X_train = X_train.apply(lambda l: ' '.join([nltk.porter.PorterStemmer().stem(word) for word in l.split()]))\n",
    "X_train = X_train.apply(lambda l: ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in nlp(l)]))\n",
    "X_train = X_train.apply(lambda l: foo.process_contraction(l))\n",
    "X_train = X_train.apply(lambda l: foo.remove_punctuations(l))\n",
    "X_train = X_train.apply(lambda l: foo.remove_stopwords(foo.process_ToktokTokenizer(l)))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "845b74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a TFIDF vectorizer and then use that trained vectorizer\n",
    "# to transform the messages in the training and test sets\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train.values)\n",
    "X_train_vect = tfidf_vect.transform(X_train.values)\n",
    "X_test_vect = tfidf_vect.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419069d9",
   "metadata": {},
   "source": [
    "##### Examming the TF-IDF vocabulary to find out extra stopwords and other problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45010528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adaptation': 294,\n",
       " 'dirk': 7070,\n",
       " 'wittenborn': 29748,\n",
       " 'book': 2994,\n",
       " 'not': 18602,\n",
       " 'read': 21635,\n",
       " 'young': 30166,\n",
       " 'finn': 9631,\n",
       " 'earl': 7847,\n",
       " 'live': 15620,\n",
       " 'mom': 17401,\n",
       " 'liz': 15635,\n",
       " 'diane': 6898,\n",
       " 'lane': 15006,\n",
       " 'cramp': 5744,\n",
       " 'low': 15873,\n",
       " 'east': 7875,\n",
       " 'side': 24164,\n",
       " 'new': 18297,\n",
       " 'york': 30151,\n",
       " 'apartment': 1260,\n",
       " 'dream': 7598,\n",
       " 'join': 14264,\n",
       " 'anthropologist': 1155,\n",
       " 'father': 9240,\n",
       " 'study': 25660,\n",
       " 'fierce': 9448,\n",
       " 'tribe': 27529,\n",
       " 'south': 24889,\n",
       " 'america': 919,\n",
       " 'boyfriend': 3132,\n",
       " 'coke': 4926,\n",
       " 'catch': 4041,\n",
       " 'score': 23301,\n",
       " 'one': 18988,\n",
       " 'customer': 6077,\n",
       " 'legitimate': 15260,\n",
       " 'masseuse': 16515,\n",
       " 'rich': 22355,\n",
       " 'mr': 17791,\n",
       " 'osborne': 19220,\n",
       " 'bail': 1994,\n",
       " 'return': 22263,\n",
       " 'full': 10311,\n",
       " 'time': 27025,\n",
       " 'personal': 20031,\n",
       " 'huge': 12735,\n",
       " 'estate': 8577,\n",
       " 'jersey': 14160,\n",
       " 'drive': 7645,\n",
       " 'limo': 15536,\n",
       " 'string': 25611,\n",
       " 'lie': 15437,\n",
       " 'back': 1916,\n",
       " 'seat': 23439,\n",
       " 'dress': 7621,\n",
       " 'hitch': 12380,\n",
       " 'way': 29228,\n",
       " 'pantie': 19616,\n",
       " 'show': 24071,\n",
       " 'lowcut': 15879,\n",
       " 'scene': 23176,\n",
       " 'exploitation': 8911,\n",
       " 'ms': 17799,\n",
       " 'may': 16614,\n",
       " 'disappoint': 7086,\n",
       " 'sorry': 24853,\n",
       " 'stuff': 25662,\n",
       " 'unfaithful': 28112,\n",
       " 'make': 16176,\n",
       " 'alist': 710,\n",
       " 'lady': 14941,\n",
       " 'talent': 26272,\n",
       " 'little': 15615,\n",
       " 'finger': 9617,\n",
       " 'streep': 25581,\n",
       " 'robert': 22528,\n",
       " 'sally': 22957,\n",
       " 'field': 9442,\n",
       " 'entire': 8429,\n",
       " 'body': 2911,\n",
       " 'give': 10846,\n",
       " 'due': 7716,\n",
       " 'arrive': 1453,\n",
       " 'friend': 10222,\n",
       " 'osbornes': 19221,\n",
       " 'grandson': 11213,\n",
       " 'bryce': 3415,\n",
       " 'coming': 5063,\n",
       " 'age': 496,\n",
       " 'girlfriend': 10822,\n",
       " 'granddaughter': 11198,\n",
       " 'maya': 16615,\n",
       " 'meanwhile': 16730,\n",
       " 'aa': 0,\n",
       " 'date': 6280,\n",
       " 'doctor': 7338,\n",
       " 'miraculously': 17206,\n",
       " 'clean': 4740,\n",
       " 'instantly': 13512,\n",
       " 'however': 12697,\n",
       " 'lot': 15796,\n",
       " 'drug': 7672,\n",
       " 'along': 812,\n",
       " 'sex': 23783,\n",
       " 'seem': 23503,\n",
       " 'like': 15502,\n",
       " 'ok': 18923,\n",
       " 'guy': 11511,\n",
       " 'get': 10726,\n",
       " 'jealous': 14105,\n",
       " 'take': 26257,\n",
       " 'hot': 12644,\n",
       " 'air': 583,\n",
       " 'balloon': 2037,\n",
       " 'race': 21421,\n",
       " 'instead': 13513,\n",
       " 'lead': 15177,\n",
       " 'tragedythe': 27395,\n",
       " 'genius': 10655,\n",
       " 'story': 25506,\n",
       " 'movie': 17671,\n",
       " 'cut': 6078,\n",
       " 'violent': 28859,\n",
       " 'act': 203,\n",
       " 'filthy': 9589,\n",
       " 'blysdale': 2883,\n",
       " 'yanomano': 30067,\n",
       " 'warrior': 29134,\n",
       " 'implausible': 13086,\n",
       " 'though': 26877,\n",
       " 'find': 9603,\n",
       " 'happen': 11731,\n",
       " 'son': 24795,\n",
       " 'merely': 16898,\n",
       " 'demand': 6597,\n",
       " 'action': 227,\n",
       " 'either': 8029,\n",
       " 'contact': 5393,\n",
       " 'authority': 1771,\n",
       " 'settle': 23756,\n",
       " 'thelma': 26672,\n",
       " 'louise': 15817,\n",
       " 'style': 25710,\n",
       " 'element': 8078,\n",
       " 'gothic': 11126,\n",
       " 'romance': 22631,\n",
       " 'revelation': 22276,\n",
       " 'village': 28830,\n",
       " 'idiot': 12938,\n",
       " 'also': 830,\n",
       " 'almost': 805,\n",
       " 'plot': 20390,\n",
       " 'character': 4264,\n",
       " 'development': 6821,\n",
       " 'prior': 20932,\n",
       " 'move': 17662,\n",
       " 'instance': 13510,\n",
       " 'pearl': 19860,\n",
       " 'kantrowitz': 14451,\n",
       " 'walk': 29040,\n",
       " 'moon': 17504,\n",
       " 'unwanted': 28386,\n",
       " 'pregnancy': 20798,\n",
       " 'feel': 9327,\n",
       " 'trap': 27458,\n",
       " 'still': 25424,\n",
       " 'minor': 17183,\n",
       " 'shortcoming': 24037,\n",
       " 'release': 21957,\n",
       " 'year': 30088,\n",
       " 'original': 19187,\n",
       " 'could': 5634,\n",
       " 'waitthere': 29032,\n",
       " 'red': 21783,\n",
       " 'carpet': 3923,\n",
       " 'moment': 17402,\n",
       " 'theater': 26657,\n",
       " 'see': 23488,\n",
       " 'whole': 29545,\n",
       " 'castexcept': 4012,\n",
       " 'director': 7052,\n",
       " 'dunne': 7766,\n",
       " 'say': 23119,\n",
       " 'film': 9480,\n",
       " 'know': 14777,\n",
       " 'promise': 21046,\n",
       " 'come': 5014,\n",
       " 'town': 27360,\n",
       " 'would': 29921,\n",
       " 'thrill': 26922,\n",
       " 'person': 20026,\n",
       " 'definite': 6513,\n",
       " 'good': 11036,\n",
       " 'picture': 20186,\n",
       " 'contender': 5408,\n",
       " 'sutherland': 26065,\n",
       " 'quite': 21400,\n",
       " 'boy': 3126,\n",
       " 'play': 20335,\n",
       " 'magnificent': 16141,\n",
       " 'always': 865,\n",
       " 'recall': 21714,\n",
       " 'two': 27777,\n",
       " 'emotional': 8201,\n",
       " 'let': 15349,\n",
       " 'fd': 9297,\n",
       " 'together': 27177,\n",
       " 'mother': 17605,\n",
       " 'twisted': 27770,\n",
       " 'fare': 9179,\n",
       " 'well': 29335,\n",
       " 'support': 25967,\n",
       " 'actress': 265,\n",
       " 'nod': 18460,\n",
       " 'work': 29849,\n",
       " 'unless': 28220,\n",
       " 'crappy': 5762,\n",
       " 'idea': 12906,\n",
       " 'shelf': 23928,\n",
       " 'must': 17939,\n",
       " 'pay': 19829,\n",
       " 'store': 25494,\n",
       " 'put': 21292,\n",
       " 'seriously': 23722,\n",
       " 'absolutely': 91,\n",
       " 'sense': 23652,\n",
       " 'heavy': 12009,\n",
       " 'definitely': 6514,\n",
       " 'something': 24772,\n",
       " 'order': 19155,\n",
       " 'watch': 29175,\n",
       " 'total': 27318,\n",
       " 'piece': 20198,\n",
       " 'garbage': 10531,\n",
       " 'much': 17808,\n",
       " 'care': 3862,\n",
       " 'tv': 27724,\n",
       " 'coma': 4999,\n",
       " 'writing': 29974,\n",
       " 'sound': 24874,\n",
       " 'yearold': 30095,\n",
       " 'acting': 210,\n",
       " 'bad': 1949,\n",
       " 'grade': 11168,\n",
       " 'school': 23251,\n",
       " 'hideous': 12219,\n",
       " 'special': 24958,\n",
       " 'effect': 7965,\n",
       " 'try': 27640,\n",
       " 'look': 15738,\n",
       " 'stupid': 25691,\n",
       " 'spend': 25003,\n",
       " 'oh': 18907,\n",
       " 'old': 18938,\n",
       " 'woman': 29778,\n",
       " 'hairdo': 11583,\n",
       " 'ugly': 27850,\n",
       " 'girl': 10818,\n",
       " 'rubber': 22759,\n",
       " 'suit': 25853,\n",
       " 'laugh': 15107,\n",
       " 'hard': 11755,\n",
       " 'someone': 24768,\n",
       " 'actually': 276,\n",
       " 'think': 26803,\n",
       " 'believe': 2419,\n",
       " 'want': 29082,\n",
       " 'start': 25290,\n",
       " 'jean': 14107,\n",
       " 'stapleton': 25260,\n",
       " 'randy': 21536,\n",
       " 'newman': 18314,\n",
       " 'song': 24799,\n",
       " 'iowa': 13742,\n",
       " 'northwest': 18587,\n",
       " 'guess': 11416,\n",
       " 'reminiscent': 22019,\n",
       " 'norman': 18570,\n",
       " 'lears': 15200,\n",
       " 'cold': 4931,\n",
       " 'turkey': 27692,\n",
       " 'ever': 8678,\n",
       " 'accord': 156,\n",
       " 'people': 19927,\n",
       " 'imdb': 13029,\n",
       " 'far': 9172,\n",
       " 'archangel': 1357,\n",
       " 'michael': 16992,\n",
       " 'pansy': 19612,\n",
       " 'milbank': 17074,\n",
       " 'motel': 17601,\n",
       " 'earth': 7860,\n",
       " 'chance': 4229,\n",
       " 'suppose': 25972,\n",
       " 'comedy': 5023,\n",
       " 'okay': 18925,\n",
       " 'thing': 26786,\n",
       " 'angel': 1051,\n",
       " 'fall': 9101,\n",
       " 'never': 18290,\n",
       " 'completely': 5166,\n",
       " 'blow': 2849,\n",
       " 'credibility': 5816,\n",
       " 'might': 17051,\n",
       " 'appeal': 1289,\n",
       " 'bring': 3309,\n",
       " 'dog': 7362,\n",
       " 'life': 15444,\n",
       " 'awe': 1838,\n",
       " 'corny': 5564,\n",
       " 'country': 5658,\n",
       " 'end': 8253,\n",
       " 'dance': 6185,\n",
       " 'travolta': 27487,\n",
       " 'big': 2618,\n",
       " 'deal': 6367,\n",
       " 'smart': 24548,\n",
       " 'even': 8661,\n",
       " 'gee': 10610,\n",
       " 'tasteless': 26366,\n",
       " 'boring': 3053,\n",
       " 'sacrilegious': 22886,\n",
       " 'fit': 9687,\n",
       " 'child': 4442,\n",
       " 'anyone': 1221,\n",
       " 'else': 8135,\n",
       " 'surprising': 26013,\n",
       " 'production': 20991,\n",
       " 'gets': 10731,\n",
       " 'day': 6309,\n",
       " 'especially': 8560,\n",
       " 'television': 26471,\n",
       " 'consider': 5352,\n",
       " 'strong': 25626,\n",
       " 'sexual': 23796,\n",
       " 'theme': 26682,\n",
       " 'explicit': 8907,\n",
       " 'lovemake': 15850,\n",
       " 'mention': 16873,\n",
       " 'lesbianism': 15326,\n",
       " 'superb': 25914,\n",
       " 'treatment': 27501,\n",
       " 'directionthe': 7050,\n",
       " 'set': 23744,\n",
       " 'costume': 5622,\n",
       " 'flawless': 9759,\n",
       " 'direction': 7043,\n",
       " 'stylish': 25716,\n",
       " 'likeable': 15503,\n",
       " 'fair': 9071,\n",
       " 'amount': 954,\n",
       " 'humor': 12775,\n",
       " 'surprisingly': 26014,\n",
       " 'dark': 6243,\n",
       " 'interlude': 13607,\n",
       " 'protagonist': 21102,\n",
       " 'really': 21668,\n",
       " 'tragic': 27396,\n",
       " 'figure': 9471,\n",
       " 'devoid': 6848,\n",
       " 'happiness': 11743,\n",
       " 'avoid': 1812,\n",
       " 'mistake': 17287,\n",
       " 'filmsshow': 9566,\n",
       " 'homosexualitylesbianism': 12511,\n",
       " 'human': 12753,\n",
       " 'allow': 766,\n",
       " 'comfortable': 5050,\n",
       " 'gay': 10594,\n",
       " 'lesbian': 15324,\n",
       " 'fill': 9476,\n",
       " 'cliche': 4778,\n",
       " 'obsess': 18783,\n",
       " 'tip': 27113,\n",
       " 'velvet': 28652,\n",
       " 'hardly': 11769,\n",
       " 'aware': 1826,\n",
       " 'meansthe': 16725,\n",
       " 'bbc': 2245,\n",
       " 'wonderful': 29802,\n",
       " 'past': 19734,\n",
       " 'adventurous': 391,\n",
       " 'period': 19990,\n",
       " 'confirm': 5280,\n",
       " 'standard': 25244,\n",
       " 'excellence': 8757,\n",
       " 'front': 10265,\n",
       " 'convict': 5471,\n",
       " 'serve': 23734,\n",
       " 'forward': 10056,\n",
       " 'case': 3973,\n",
       " 'unit': 28202,\n",
       " 'information': 13363,\n",
       " 'murder': 17890,\n",
       " 'policeman': 20497,\n",
       " 'commit': 5097,\n",
       " 'sean': 23427,\n",
       " 'cooper': 5504,\n",
       " 'cop': 5510,\n",
       " 'solve': 24749,\n",
       " 'naturally': 18119,\n",
       " 'detective': 6788,\n",
       " 'evidence': 8712,\n",
       " 'help': 12069,\n",
       " 'puzzle': 21297,\n",
       " 'frustrate': 10282,\n",
       " 'colleaguesin': 4948,\n",
       " 'flashback': 9733,\n",
       " 'baptism': 2093,\n",
       " 'james': 14036,\n",
       " 'brunos': 3400,\n",
       " 'baby': 1897,\n",
       " 'jimmy': 14198,\n",
       " 'partner': 19703,\n",
       " 'tension': 26523,\n",
       " 'godfather': 10967,\n",
       " 'dishevel': 7173,\n",
       " 'late': 15066,\n",
       " 'rite': 22470,\n",
       " 'eileen': 8022,\n",
       " 'bruno': 3399,\n",
       " 'appear': 1295,\n",
       " 'happy': 11745,\n",
       " 'real': 21646,\n",
       " 'mystery': 17981,\n",
       " 'reveal': 22272,\n",
       " 'drink': 7637,\n",
       " 'backyard': 1945,\n",
       " 'kiss': 14717,\n",
       " 'husband': 12819,\n",
       " 'shocking': 24003,\n",
       " 'yet': 30124,\n",
       " 'respond': 22201,\n",
       " 'willinglysomehow': 29644,\n",
       " 'station': 25314,\n",
       " 'become': 2313,\n",
       " 'center': 4150,\n",
       " 'gossip': 11118,\n",
       " 'endear': 8261,\n",
       " 'superior': 25939,\n",
       " 'discover': 7133,\n",
       " 'involvement': 13734,\n",
       " 'criminal': 5857,\n",
       " 'area': 1377,\n",
       " 'control': 5451,\n",
       " 'business': 3580,\n",
       " 'realize': 21664,\n",
       " 'man': 16239,\n",
       " 'excuse': 8812,\n",
       " 'free': 10176,\n",
       " 'scum': 23410,\n",
       " 'bag': 1983,\n",
       " 'haul': 11868,\n",
       " 'pressure': 20859,\n",
       " 'homosexuality': 12510,\n",
       " 'honest': 12514,\n",
       " 'anything': 1230,\n",
       " 'queer': 21349,\n",
       " 'mccree': 16653,\n",
       " 'jurisdiction': 14398,\n",
       " 'complicated': 5175,\n",
       " 'long': 15717,\n",
       " 'line': 15553,\n",
       " 'irish': 13761,\n",
       " 'police': 20495,\n",
       " 'force': 9945,\n",
       " 'kill': 14651,\n",
       " 'homosexual': 12509,\n",
       " 'condition': 5257,\n",
       " 'peer': 19887,\n",
       " 'dirty': 7073,\n",
       " 'moneytom': 17430,\n",
       " 'petit': 20072,\n",
       " 'write': 29964,\n",
       " 'portrayal': 20623,\n",
       " 'officer': 18871,\n",
       " 'closet': 4825,\n",
       " 'secret': 23462,\n",
       " 'love': 15829,\n",
       " 'another': 1134,\n",
       " 'fellow': 9355,\n",
       " 'frank': 10130,\n",
       " 'account': 159,\n",
       " 'serious': 23720,\n",
       " 'matter': 16581,\n",
       " 'talk': 26287,\n",
       " 'sometimes': 24783,\n",
       " 'involve': 13730,\n",
       " 'fear': 9298,\n",
       " 'reprisal': 22109,\n",
       " 'sponsor': 25090,\n",
       " 'network': 18279,\n",
       " 'dare': 6236,\n",
       " 'present': 20841,\n",
       " 'situation': 24338,\n",
       " 'jeannot': 14113,\n",
       " 'szwarc': 26209,\n",
       " 'sensitive': 23662,\n",
       " 'approach': 1323,\n",
       " 'thorny': 26870,\n",
       " 'issue': 13847,\n",
       " 'without': 29740,\n",
       " 'sensationalism': 23648,\n",
       " 'different': 6955,\n",
       " 'teamthere': 26411,\n",
       " 'rare': 21570,\n",
       " 'chad': 4192,\n",
       " 'everett': 8683,\n",
       " 'appearance': 1296,\n",
       " 'right': 22411,\n",
       " 'target': 26351,\n",
       " 'touch': 27329,\n",
       " 'sentimentality': 23677,\n",
       " 'hand': 11670,\n",
       " 'shane': 23860,\n",
       " 'johnson': 14259,\n",
       " 'excellent': 8759,\n",
       " 'contribution': 5445,\n",
       " 'cast': 4000,\n",
       " 'marvelous': 16478,\n",
       " 'include': 13188,\n",
       " 'around': 1436,\n",
       " 'performance': 19973,\n",
       " 'everyone': 8698,\n",
       " 'szwarcs': 26210,\n",
       " 'directionin': 7045,\n",
       " 'episode': 8471,\n",
       " 'nick': 18353,\n",
       " 'vera': 28679,\n",
       " 'close': 4821,\n",
       " 'neighbor': 18233,\n",
       " 'basketball': 2182,\n",
       " 'player': 20341,\n",
       " 'ball': 2027,\n",
       " 'away': 1829,\n",
       " 'head': 11919,\n",
       " 'contain': 5396,\n",
       " 'hole': 12449,\n",
       " 'massive': 16518,\n",
       " 'truck': 27609,\n",
       " 'reckon': 21737,\n",
       " 'top': 27266,\n",
       " 'priority': 20933,\n",
       " 'horror': 12600,\n",
       " 'elderly': 8055,\n",
       " 'sister': 24319,\n",
       " 'rural': 22829,\n",
       " 'england': 8331,\n",
       " 'keep': 14537,\n",
       " 'brother': 3373,\n",
       " 'cellar': 4135,\n",
       " 'since': 24264,\n",
       " 'escape': 8543,\n",
       " 'spree': 25122,\n",
       " 'focus': 9873,\n",
       " 'military': 17091,\n",
       " 'home': 12475,\n",
       " 'nearby': 18167,\n",
       " 'repeat': 22071,\n",
       " 'strangely': 25558,\n",
       " 'army': 1427,\n",
       " 'doubt': 7495,\n",
       " 'sincerity': 24271,\n",
       " 'die': 6930,\n",
       " 'whether': 29492,\n",
       " 'near': 18166,\n",
       " 'suspenseful': 26054,\n",
       " 'tedious': 26440,\n",
       " 'remind': 22013,\n",
       " 'arsenic': 1465,\n",
       " 'lace': 14927,\n",
       " 'blackcomedy': 2727,\n",
       " 'classic': 4704,\n",
       " 'halfinsane': 11621,\n",
       " 'sibling': 24145,\n",
       " 'goofy': 11075,\n",
       " 'killing': 14668,\n",
       " 'beast': 2276,\n",
       " 'mean': 16709,\n",
       " 'less': 15331,\n",
       " 'crazy': 5789,\n",
       " 'early': 7849,\n",
       " 'amateurish': 878,\n",
       " 'cheap': 4356,\n",
       " 'neat': 18178,\n",
       " 'attempt': 1680,\n",
       " 'build': 3473,\n",
       " 'many': 16357,\n",
       " 'oldladie': 18948,\n",
       " 'ol': 18935,\n",
       " 'rarely': 21572,\n",
       " 'seek': 23500,\n",
       " 'title': 27138,\n",
       " 'flora': 9822,\n",
       " 'robson': 22551,\n",
       " 'recognize': 21745,\n",
       " 'buff': 3461,\n",
       " 'image': 13001,\n",
       " 'queen': 21344,\n",
       " 'legendary': 15251,\n",
       " 'errol': 8527,\n",
       " 'flynn': 9861,\n",
       " 'swashbuckler': 26094,\n",
       " 'sea': 23417,\n",
       " 'hawk': 11891,\n",
       " 'mann': 16302,\n",
       " 'photograph': 20146,\n",
       " 'alberta': 647,\n",
       " 'rocky': 22575,\n",
       " 'mountain': 17643,\n",
       " 'fashion': 9214,\n",
       " 'stewart': 25407,\n",
       " 'walter': 29066,\n",
       " 'brennan': 3262,\n",
       " 'enjoyable': 8352,\n",
       " 'hollywood': 12458,\n",
       " 'mountie': 17647,\n",
       " 'tell': 26475,\n",
       " 'dawson': 6308,\n",
       " 'city': 4656,\n",
       " 'yukon': 30198,\n",
       " 'elect': 8058,\n",
       " 'marshal': 16456,\n",
       " 'yes': 30119,\n",
       " 'enforce': 8319,\n",
       " 'law': 15143,\n",
       " 'gunfighter': 11463,\n",
       " 'battle': 2224,\n",
       " 'street': 25582,\n",
       " 'nothing': 18617,\n",
       " 'remotely': 22029,\n",
       " 'resemble': 22149,\n",
       " 'canadian': 3762,\n",
       " 'border': 3038,\n",
       " 'klondike': 14745,\n",
       " 'gold': 10998,\n",
       " 'rush': 22831,\n",
       " 'company': 5126,\n",
       " 'deadwood': 6361,\n",
       " 'north': 18576,\n",
       " 'american': 921,\n",
       " 'wild': 29611,\n",
       " 'westcanadian': 29440,\n",
       " 'viewer': 28794,\n",
       " 'prepare': 20821,\n",
       " 'reefer': 21822,\n",
       " 'madness': 16105,\n",
       " 'type': 27810,\n",
       " 'howl': 12700,\n",
       " 'ludicrous': 15938,\n",
       " 'shake': 23834,\n",
       " 'disgust': 7164,\n",
       " 'funniest': 10359,\n",
       " 'forever': 9982,\n",
       " 'chritopher': 4549,\n",
       " 'guest': 11423,\n",
       " 'truly': 27624,\n",
       " 'talented': 26275,\n",
       " 'gift': 10775,\n",
       " 'dumb': 7738,\n",
       " 'funnydumb': 10367,\n",
       " 'combination': 5007,\n",
       " 'endthis': 8304,\n",
       " 'mockumentary': 17343,\n",
       " 'follow': 9894,\n",
       " 'array': 1446,\n",
       " 'compete': 5146,\n",
       " 'kennel': 14567,\n",
       " 'club': 4842,\n",
       " 'parker': 19669,\n",
       " 'posey': 20631,\n",
       " 'fred': 10170,\n",
       " 'willard': 29630,\n",
       " 'eugene': 8628,\n",
       " 'levy': 15389,\n",
       " 'catherine': 4059,\n",
       " 'ohara': 18909,\n",
       " 'john': 14253,\n",
       " 'higgen': 12226,\n",
       " 'mckean': 16678,\n",
       " 'larry': 15048,\n",
       " 'miller': 17105,\n",
       " 'bob': 2901,\n",
       " 'balaban': 2011,\n",
       " 'jennifer': 14141,\n",
       " 'coolidge': 5495,\n",
       " 'ton': 27218,\n",
       " 'funny': 10362,\n",
       " 'bear': 2268,\n",
       " 'personality': 20032,\n",
       " 'widescreen': 29584,\n",
       " 'view': 28793,\n",
       " 'actual': 273,\n",
       " 'documentary': 7345,\n",
       " 'probably': 20954,\n",
       " 'add': 299,\n",
       " 'hilarity': 12271,\n",
       " 'poorly': 20564,\n",
       " 'direct': 7039,\n",
       " 'asleep': 1551,\n",
       " 'minute': 17194,\n",
       " 'joke': 14269,\n",
       " 'interesting': 13597,\n",
       " 'angle': 1066,\n",
       " 'fetched': 9403,\n",
       " 'point': 20458,\n",
       " 'ridiculous': 22387,\n",
       " 'overlook': 19409,\n",
       " 'capture': 3843,\n",
       " 'attention': 1686,\n",
       " 'amazed': 883,\n",
       " 'stunt': 25683,\n",
       " 'wish': 29711,\n",
       " 'casting': 4014,\n",
       " 'music': 17920,\n",
       " 'disappointing': 7093,\n",
       " 'scale': 23136,\n",
       " 'horrible': 12590,\n",
       " 'brenda': 3260,\n",
       " 'talente': 26274,\n",
       " 'kind': 14685,\n",
       " 'laughable': 15108,\n",
       " 'fighting': 9466,\n",
       " 'pose': 20630,\n",
       " 'loud': 15806,\n",
       " 'directing': 7041,\n",
       " 'example': 8743,\n",
       " 'part': 19684,\n",
       " 'enemy': 8313,\n",
       " 'turn': 27698,\n",
       " 'evil': 8716,\n",
       " 'villain': 28832,\n",
       " 'possese': 20641,\n",
       " 'voice': 28937,\n",
       " 'incredibly': 13224,\n",
       " 'wendys': 29421,\n",
       " 'songteacher': 24803,\n",
       " 'teacher': 26398,\n",
       " 'possess': 20642,\n",
       " 'monk': 17440,\n",
       " 'pretty': 20877,\n",
       " 'sumamrize': 25872,\n",
       " 'originally': 19191,\n",
       " 'call': 3699,\n",
       " 'changer': 4244,\n",
       " 'nostril': 18600,\n",
       " 'picker': 20176,\n",
       " 'construct': 5381,\n",
       " 'tale': 26270,\n",
       " 'loner': 15714,\n",
       " 'name': 18036,\n",
       " 'joe': 14243,\n",
       " 'bukowski': 3480,\n",
       " 'carl': 3893,\n",
       " 'zschering': 30292,\n",
       " 'em': 8155,\n",
       " 'unable': 27900,\n",
       " 'socially': 24683,\n",
       " 'interact': 13581,\n",
       " 'bump': 3510,\n",
       " 'tramp': 27418,\n",
       " 'teach': 26397,\n",
       " 'vietnamese': 28791,\n",
       " 'chant': 4252,\n",
       " 'whistle': 29522,\n",
       " 'london': 15704,\n",
       " 'bridge': 3285,\n",
       " 'whilst': 29504,\n",
       " 'hop': 12553,\n",
       " 'epileptic': 8468,\n",
       " 'morris': 17573,\n",
       " 'dancer': 6186,\n",
       " 'nonetheless': 18506,\n",
       " 'hey': 12196,\n",
       " 'presto': 20861,\n",
       " 'ideally': 12919,\n",
       " 'need': 18200,\n",
       " 'attract': 1699,\n",
       " 'ideal': 12913,\n",
       " 'world': 29871,\n",
       " 'releasedthe': 21959,\n",
       " 'asylum': 1636,\n",
       " 'dub': 7699,\n",
       " 'hokum': 12439,\n",
       " 'mind': 17131,\n",
       " 'numb': 18705,\n",
       " 'ham': 11652,\n",
       " 'biscuit': 2687,\n",
       " 'fact': 9041,\n",
       " 'goddamn': 10963,\n",
       " 'cookie': 5487,\n",
       " 'jar': 14070,\n",
       " 'terribly': 26565,\n",
       " 'script': 23381,\n",
       " 'dialogue': 6886,\n",
       " 'deliver': 6573,\n",
       " 'braindead': 3171,\n",
       " 'actor': 251,\n",
       " 'predictable': 20784,\n",
       " 'twist': 27768,\n",
       " 'absurd': 99,\n",
       " 'go': 10949,\n",
       " 'nonsensical': 18542,\n",
       " 'tangent': 26322,\n",
       " 'decide': 6438,\n",
       " 'change': 4239,\n",
       " 'content': 5409,\n",
       " 'murderer': 17893,\n",
       " 'cannibal': 3785,\n",
       " 'eat': 7885,\n",
       " 'victim': 28762,\n",
       " 'highlight': 12242,\n",
       " 'terrible': 26558,\n",
       " 'pick': 20175,\n",
       " 'hooker': 12542,\n",
       " 'steven': 25399,\n",
       " 'andrew': 1036,\n",
       " 'next': 18326,\n",
       " 'defie': 6505,\n",
       " 'belief': 2411,\n",
       " 'react': 21630,\n",
       " 'benny': 2482,\n",
       " 'hillesquire': 12279,\n",
       " 'chase': 4333,\n",
       " 'bunch': 3514,\n",
       " 'squirty': 25174,\n",
       " 'dildo': 6991,\n",
       " 'trip': 27556,\n",
       " 'doll': 7393,\n",
       " 'god': 10958,\n",
       " 'patrick': 19784,\n",
       " 'matthew': 16591,\n",
       " 'stephen': 25376,\n",
       " 'hodge': 12426,\n",
       " 'least': 15204,\n",
       " 'pave': 19822,\n",
       " 'priceless': 20896,\n",
       " 'male': 16198,\n",
       " 'report': 22093,\n",
       " 'incident': 13182,\n",
       " 'curly': 6044,\n",
       " 'haired': 11587,\n",
       " 'bit': 2695,\n",
       " 'shop': 24022,\n",
       " 'uniform': 28168,\n",
       " 'hilarious': 12264,\n",
       " 'inability': 13141,\n",
       " 'satisfactionapart': 23072,\n",
       " 'monotonous': 17460,\n",
       " 'slash': 24432,\n",
       " 'flick': 9783,\n",
       " 'complete': 5164,\n",
       " 'bore': 3040,\n",
       " 'dvd': 7805,\n",
       " 'trailer': 27400,\n",
       " 'exciting': 8790,\n",
       " 'normally': 18568,\n",
       " 'fast': 9219,\n",
       " 'main': 16159,\n",
       " 'sequence': 23691,\n",
       " 'simply': 24253,\n",
       " 'stab': 25184,\n",
       " 'repeatedly': 22072,\n",
       " 'forget': 9989,\n",
       " 'quick': 21362,\n",
       " 'utilize': 28514,\n",
       " 'fadeout': 9054,\n",
       " 'limit': 15529,\n",
       " 'form': 10006,\n",
       " 'suspense': 26051,\n",
       " 'already': 825,\n",
       " 'nonreaction': 18536,\n",
       " 'chop': 4506,\n",
       " 'relish': 21982,\n",
       " 'word': 29840,\n",
       " 'uncut': 27983,\n",
       " 'blessing': 2783,\n",
       " 'agonizing': 535,\n",
       " 'cinematic': 4617,\n",
       " 'torture': 27306,\n",
       " 'unedited': 28087,\n",
       " 'midsummer': 17042,\n",
       " 'entertaining': 8402,\n",
       " 'hate': 11852,\n",
       " 'versionto': 28718,\n",
       " 'sum': 25871,\n",
       " 'unentertaining': 28094,\n",
       " 'richard': 22356,\n",
       " 'hammond': 11662,\n",
       " 'clock': 4813,\n",
       " 'dismal': 7193,\n",
       " 'tinny': 27105,\n",
       " 'soundtrack': 24878,\n",
       " 'dubbing': 7700,\n",
       " 'fool': 9919,\n",
       " 'box': 3116,\n",
       " 'label': 14919,\n",
       " 'cult': 6012,\n",
       " 'qualify': 21322,\n",
       " 'letsuseshittyhorrordvdsforcoffeecoaster': 15359,\n",
       " 'reedite': 21819,\n",
       " 'stay': 25327,\n",
       " 'induce': 13291,\n",
       " 'mess': 16926,\n",
       " 'first': 9656,\n",
       " 'teenager': 26448,\n",
       " 'metal': 16946,\n",
       " 'rule': 22797,\n",
       " 'trick': 27535,\n",
       " 'treat': 27499,\n",
       " 'every': 8692,\n",
       " 'rock': 22556,\n",
       " 'feature': 9309,\n",
       " 'skippy': 24401,\n",
       " 'family': 9125,\n",
       " 'tie': 26992,\n",
       " 'gene': 10631,\n",
       " 'simmon': 24236,\n",
       " 'ozzy': 19495,\n",
       " 'osbourne': 19222,\n",
       " 'preacher': 20756,\n",
       " 'wrong': 29977,\n",
       " 'backwards': 1940,\n",
       " 'message': 16927,\n",
       " 'vinyl': 28853,\n",
       " 'use': 28479,\n",
       " 'record': 21763,\n",
       " 'eddie': 7921,\n",
       " 'listen': 15598,\n",
       " 'rockstar': 22570,\n",
       " 'begin': 2367,\n",
       " 'scary': 23165,\n",
       " 'monster': 17466,\n",
       " 'speaker': 24952,\n",
       " 'stereo': 25383,\n",
       " 'becomes': 2315,\n",
       " 'hope': 12555,\n",
       " 'mine': 17151,\n",
       " 'later': 15075,\n",
       " 'favorite': 9278,\n",
       " 'finally': 9597,\n",
       " 'receive': 21721,\n",
       " 'today': 27165,\n",
       " 'pleased': 20363,\n",
       " 'announce': 1117,\n",
       " 'theatrical': 26663,\n",
       " 'version': 28712,\n",
       " 'previous': 20889,\n",
       " 'review': 22294,\n",
       " 'famous': 9136,\n",
       " 'edit': 7935,\n",
       " 'somehow': 24762,\n",
       " 'onto': 19067,\n",
       " 'vhs': 28737,\n",
       " 'sometime': 24782,\n",
       " 'wb': 29255,\n",
       " 'correct': 5579,\n",
       " 'error': 8531,\n",
       " 'airplane': 595,\n",
       " 'restroom': 22220,\n",
       " 'matt': 16578,\n",
       " 'lattanzis': 15097,\n",
       " 'bare': 2115,\n",
       " 'butt': 3602,\n",
       " 'hotel': 12649,\n",
       " 'room': 22668,\n",
       " 'jacqueline': 14003,\n",
       " 'bisset': 2691,\n",
       " 'merry': 16916,\n",
       " 'candice': 3770,\n",
       " 'bergen': 2497,\n",
       " 'ct': 5986,\n",
       " 'crisp': 5872,\n",
       " 'clear': 4748,\n",
       " 'digital': 6979,\n",
       " 'transfer': 27429,\n",
       " 'vintage': 28851,\n",
       " 'featurette': 9312,\n",
       " 'location': 15660,\n",
       " 'interview': 13648,\n",
       " 'purchase': 21257,\n",
       " 'glad': 10858,\n",
       " 'dvda': 7806,\n",
       " 'worth': 29915,\n",
       " 'wait': 29024,\n",
       " 'thank': 26618,\n",
       " 'warner': 29123,\n",
       " 'bros': 3367,\n",
       " 'produce': 20984,\n",
       " 'broadcast': 3333,\n",
       " 'mid': 17019,\n",
       " 'grow': 11380,\n",
       " 'middle': 17021,\n",
       " 'mel': 16803,\n",
       " 'diner': 7015,\n",
       " 'artificial': 1483,\n",
       " 'nostalgia': 18597,\n",
       " 'fonz': 9915,\n",
       " 'course': 5678,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b52f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional_stopwords = ['also', 'fd', 'nan', 'oh', 'ok', 'ms', 'mr', 'aa', 'yet', 'become', 'fd', 'ol', 'em', 'hey',\n",
    "#                        'wb', 'ct']\n",
    "# foo.stopword_list.append(additional_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f50a92",
   "metadata": {},
   "source": [
    "##### Applying Random Forest with default hyper-parameters to evaluate the quality of the preprocessing process\n",
    "\n",
    "Go back to add more steps to make a better evaluating score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbf56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a basic Random Forest model on these vectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect, y_train.values.flatten())\n",
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70948703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.798 / Recall: 0.866 / Accuracy: 0.823\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of the model on the holdout test set\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=\"positive\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"positive\")\n",
    "\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd3208",
   "metadata": {},
   "source": [
    "### Model training on normalized corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ccf3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/francis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: (25000, 2)\n",
      "test site split random_state : 9314\n",
      "training data size: (12500,)\n"
     ]
    }
   ],
   "source": [
    "class Driver:\n",
    "    def __init__(self, testing=False, frac=0.01, test_split_size=0.1):\n",
    "        self.foo = TextPreprocessing()\n",
    "        if testing:\n",
    "            self.foo.doc = self.foo.doc.sample(frac=frac, replace=False, random_state=0)\n",
    "            print('DOWN SAMPLING:')\n",
    "        print(\"sample size: %s\" % str(self.foo.doc.shape))\n",
    "        \n",
    "        r = random.randint(1, 10000)\n",
    "        print(\"test site split random_state : %d\" % r)\n",
    "        self.X = self.foo.doc['review']\n",
    "        self.y = self.foo.doc['sentiment']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "            train_test_split(self.X, self.y, test_size=test_split_size, random_state=r, stratify=self.y)\n",
    "        print(\"training data size: %s\" % str(self.X_train.shape))\n",
    "        \n",
    "        self.X_train = self.X_train.reset_index(drop=True)\n",
    "        self.X_test = self.X_test.reset_index(drop=True)\n",
    "        pass\n",
    "\n",
    "    def text_processing(self):\n",
    "        print('remove html structures ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: BeautifulSoup(l, \"html.parser\").get_text())\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('unicodedata to NFKD ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: unicodedata.normalize('NFKD', l))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('remove single charactors ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: re.sub(r'[^a-zA-Z0-9\\s]', '', l))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('remove all the numbers ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: re.sub(r'[0-9]+', '', l))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('remove punctuation structures ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: re.sub('\\[[^]]*\\]', '', l))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('lower case ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: l.lower())\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "#         print('stemming ... ', end='')\n",
    "#         t = time()\n",
    "#         self.X_train = self.X_train.apply(lambda l: ' '.join([nltk.porter.PorterStemmer().stem(word) for word in l.split()]))\n",
    "#         print('time cost %.2fs' % (time() - t))\n",
    "        print('lemmatization ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in nlp(l)]))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('expand contractions ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: self.foo.process_contraction(l))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('remove all punctuations ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: self.foo.remove_punctuations(l))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print('tokenization ... ', end='')\n",
    "        t = time()\n",
    "        self.X_train = self.X_train.apply(lambda l: self.foo.remove_stopwords(self.foo.process_ToktokTokenizer(l)))\n",
    "        print('time cost %.2fs' % (time() - t))\n",
    "        print()\n",
    "        pass\n",
    "\n",
    "    def tfidf_vectorizer(self):\n",
    "        tfidf_vect = TfidfVectorizer()\n",
    "        tfidf_vect.fit(self.X_train.values)\n",
    "        X_train_vect = tfidf_vect.transform(self.X_train.values)\n",
    "        X_test_vect = tfidf_vect.transform(self.X_test.values)\n",
    "        return X_train_vect, X_test_vect\n",
    "\n",
    "    def model_select(self, results):\n",
    "        print(\"Now the best model is\")\n",
    "        best_model_name = None\n",
    "        best_accuracy = 0.0\n",
    "        self.__print_title()\n",
    "        for _, tup in enumerate(results):\n",
    "            self.__print_result(tup)\n",
    "            name = tup[0]\n",
    "            accuracy = tup[1][2]\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model_name = name\n",
    "        \n",
    "        algo = best_model_name.split(' ')[0]\n",
    "        print(\n",
    "            \"%s received the highest average performance with accuracy %.4f. Therefore %s is the most suitable model.\\n\" % (\n",
    "            algo, best_accuracy, algo))\n",
    "\n",
    "    def evaluating(self, callable_, verbose=0):\n",
    "        self.__print_title()\n",
    "        buffer = []\n",
    "        name = None\n",
    "        # pred_lst = []\n",
    "        for _ in range(5):\n",
    "            name, clf = callable_(self.X_train, self.y_train,\n",
    "                                  random_state=random.randint(1, 10000), verbose=verbose)\n",
    "            start = time()\n",
    "            y_pred = clf.predict(self.X_test)\n",
    "            # pred_lst.append(y_pred)\n",
    "            cost = (time() - start) * 1000\n",
    "            # tmp_params = clf.cv_results_['params'][clf.best_index_]\n",
    "            tup = (\n",
    "                round(clf.cv_results_['mean_test_score'][clf.best_index_], 3),\n",
    "                round(clf.cv_results_['std_test_score'][clf.best_index_] * 2, 3),\n",
    "                # round(accuracy_score(self.y_test, y_pred), 3),\n",
    "                round((y_pred==self.y_test).sum()/len(y_pred), 3),\n",
    "                round(precision_score(self.y_test, y_pred, pos_label=\"positive\"), 3),\n",
    "                round(recall_score(self.y_test, y_pred, pos_label=\"positive\"), 3),\n",
    "                round(cost, 3),\n",
    "            )\n",
    "            buffer.append(np.array(tup))\n",
    "            self.__print_result((name, tup))\n",
    "        tup = np.array(buffer).mean(axis=0)\n",
    "        self.__print_result((\"%s avg\" % name, tup))\n",
    "        print()\n",
    "        # self.df[name] = pd.DataFrame(pred_lst).mode().values.flatten()\n",
    "        return \"%s avg\" % name, tup\n",
    "\n",
    "    @staticmethod\n",
    "    def __print_title():\n",
    "        print(\"%15s\\t%10s\\t%10s\\t%10s\\t%10s\\t%10s\\t%10s\" % (\n",
    "            \"model\", \"mean\", \"std\", \"accuracy\", \"precision\", \"recall\", \"latency\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def __print_result(tup):\n",
    "        name, r = tup\n",
    "        if name.find(\"avg\") >= 0:\n",
    "            std = \"\"\n",
    "        else:\n",
    "            std = \"+/-%.3f\" % r[1]\n",
    "        print(\"%15s\\t%10s\\t%10s\\t%10s\\t%10s\\t%10s\\t%10s\" % (\n",
    "            \"%s\" % name, \"%.3f\" % r[0], std, \"%.3f\" % r[2], \"%.3f\" % r[3], \"%.3f\" % r[4], \"%.3f ms\" % r[5]))\n",
    "\n",
    "    def evaluating_model(self, clf):\n",
    "        pred = clf.predict(self.X_test)\n",
    "        print('Training set score: {:.4f}'.format(clf.score(self.X_train, self.y_train)))\n",
    "        print('Test set score: {:.4f}'.format(clf.score(self.X_test, self.y_test)))\n",
    "        print('Model accuracy score: {0:0.4f}'.format(accuracy_score(self.y_test, pred)))\n",
    "        print(classification_report(self.y_test, pred))\n",
    "        pass\n",
    "    \n",
    "    def train_LR(self, x, y, random_state=0, verbose=0):\n",
    "        model = LogisticRegression()\n",
    "        params = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1e4]\n",
    "        }\n",
    "        k_fold = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "        clf = self.search_cv(model, params, k_fold, verbose=verbose)\n",
    "        clf.fit(x, y)\n",
    "        return \"LR\", clf\n",
    "\n",
    "    def train_DT(self, x, y, random_state=0, verbose=0):\n",
    "        model = DecisionTreeClassifier()\n",
    "        params = {\n",
    "            'max_depth': [2, 3, 5, 10, 20],\n",
    "            'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "            'criterion': [\"gini\", \"entropy\"]\n",
    "        }\n",
    "        k_fold = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "        clf = self.search_cv(model, params, k_fold, verbose=verbose)\n",
    "        clf.fit(x, y)\n",
    "        return \"DT\", clf\n",
    "\n",
    "    def train_NB(self, x, y, random_state=0, verbose=0):\n",
    "        model = GaussianNB()\n",
    "        params = {\n",
    "            'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "        }\n",
    "        k_fold = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "        clf = self.search_cv(model, params, k_fold, verbose=verbose)\n",
    "        clf.fit(x, y)\n",
    "        return \"NB\", clf\n",
    "    \n",
    "    def train_RF(self, x, y, random_state=0, verbose=0):\n",
    "        model = RandomForestClassifier()\n",
    "        params = {\n",
    "            'bootstrap': [True, False],\n",
    "            'max_depth': [2, 4, 8, 16, 32],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'n_estimators': [10, 20, 50, 100, 200],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "        # scoring = {\n",
    "        #     \"Accuracy\": make_scorer(accuracy_score),\n",
    "        #     \"mean_absolute_error\": make_scorer(mean_absolute_error),\n",
    "        #     \"mean_squared_error\": make_scorer(mean_squared_error),\n",
    "        #     \"r2_score\": make_scorer(r2_score),\n",
    "        # }\n",
    "        k_fold = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "        clf = self.search_cv(model, params, k_fold, verbose=verbose)\n",
    "        clf.fit(x, y)\n",
    "        return \"RF\", clf\n",
    "\n",
    "    def train_XGB(self, x, y, random_state=0, verbose=0):\n",
    "        model = XGBClassifier(eval_metric='logloss')\n",
    "        params = {\n",
    "            \"learning_rate\": [0.001, 0.01, 0.1, 1],\n",
    "            \"max_depth\": [2,4,6,8,10],\n",
    "            \"min_child_weight\": range(1, 10),\n",
    "            \"gamma\": np.arange(0, 0.7, 0.2),\n",
    "            \"colsample_bytree\": np.arange(0.1, 1.1, 0.1),\n",
    "            \"n_estimators\": [10,20,50,100,200,500]\n",
    "        }\n",
    "        k_fold = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "        clf = self.search_cv(model, params, k_fold, verbose=verbose)\n",
    "        clf.fit(x, y)\n",
    "        return \"XGB\", clf\n",
    "        \n",
    "    @staticmethod\n",
    "    def search_cv(model, params, fold, verbose=0):\n",
    "        return RandomizedSearchCV(model, params, cv=fold, verbose=verbose, return_train_score=True, )\n",
    "        # return RandomizedSearchCV(model, params, cv=fold, verbose=0,\n",
    "        #                           scoring=scoring, refit=list(scoring.items())[0][0], return_train_score=True, )\n",
    "\n",
    "\n",
    "go = Driver(testing=False, frac=0.2, test_split_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68638f4",
   "metadata": {},
   "source": [
    "##### Preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6ed82f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove html structures ... time cost 1.71s\n",
      "unicodedata to NFKD ... time cost 0.04s\n",
      "remove single charactors ... time cost 0.24s\n",
      "remove all the numbers ... time cost 0.31s\n",
      "remove punctuation structures ... time cost 0.01s\n",
      "lower case ... time cost 0.02s\n",
      "lemmatization ... time cost 310.60s\n",
      "expand contractions ... time cost 16.59s\n",
      "remove all punctuations ... time cost 0.10s\n",
      "tokenization ... time cost 13.41s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "go.text_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e2bdd",
   "metadata": {},
   "source": [
    "##### Perform TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865418c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "go.X_train, go.X_test = go.tfidf_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ab6cb",
   "metadata": {},
   "source": [
    "##### Model Selection with RandomizedSearchCV and Stratifie K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "396f5f70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model\t      mean\t       std\t  accuracy\t precision\t    recall\t   latency\n",
      "            XGB\t     0.834\t  +/-0.014\t     0.801\t     0.751\t     0.899\t 75.715 ms\n",
      "            XGB\t     0.843\t  +/-0.018\t     0.817\t     0.775\t     0.893\t 81.959 ms\n",
      "            XGB\t     0.852\t  +/-0.008\t     0.829\t     0.785\t     0.904\t 85.254 ms\n",
      "            XGB\t     0.837\t  +/-0.007\t     0.806\t     0.757\t     0.901\t 85.967 ms\n",
      "            XGB\t     0.828\t  +/-0.019\t     0.810\t     0.781\t     0.861\t 74.601 ms\n",
      "        XGB avg\t     0.839\t          \t     0.813\t     0.770\t     0.892\t 80.699 ms\n",
      "\n",
      "          model\t      mean\t       std\t  accuracy\t precision\t    recall\t   latency\n",
      "             RF\t     0.826\t  +/-0.010\t     0.787\t     0.727\t     0.919\t696.998 ms\n",
      "             RF\t     0.847\t  +/-0.016\t     0.805\t     0.741\t     0.936\t888.103 ms\n",
      "             RF\t     0.829\t  +/-0.004\t     0.783\t     0.720\t     0.927\t363.059 ms\n",
      "             RF\t     0.839\t  +/-0.014\t     0.802\t     0.738\t     0.938\t715.411 ms\n",
      "             RF\t     0.838\t  +/-0.018\t     0.794\t     0.729\t     0.937\t767.681 ms\n",
      "         RF avg\t     0.836\t          \t     0.794\t     0.731\t     0.931\t686.250 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr = [\n",
    "    go.evaluating(go.train_XGB, verbose=0),\n",
    "    go.evaluating(go.train_RF, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081592ea",
   "metadata": {},
   "source": [
    "##### Report of the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52e51fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the best model is\n",
      "          model\t      mean\t       std\t  accuracy\t precision\t    recall\t   latency\n",
      "        XGB avg\t     0.839\t          \t     0.813\t     0.770\t     0.892\t 80.699 ms\n",
      "         RF avg\t     0.836\t          \t     0.794\t     0.731\t     0.931\t686.250 ms\n",
      "XGB received the highest average performance with accuracy 0.8126. Therefore XGB is the most suitable model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "go.model_select(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925197d",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06981e",
   "metadata": {},
   "source": [
    "A normalized corpus is required for NLP Process. So I applied several steps to raw text to normalize it. Besides, high-frequency stopwords will have a detrimental impact on the model's ability to predict outcomes. To further enhance the document preprocessing, I looked through the TF-IDF vector vocabulary to add some more stopwords to the stopwords list. Then I apply Random Forest on this normalized corpus to assess how well the preparation was done and repeat previous steps to enhance the performance of the corpus.\n",
    "\n",
    "Applying lemmatization or stemming is very helpful for targeting the intended meaning of context. And after some experiments, I decide to apply lemmatization nor stemming for a better accuracy score, about 2%.\n",
    "\n",
    "After all the efforts shows in this module, XGB received the highest average performance with accuracy 0.8126. Therefore, XGB is the most suitable model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
