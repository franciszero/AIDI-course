{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["5ANNeGFj4bLU","PBIpDYsPHGNk","NOb_oHzaQca6","YaMmO6202egv","DyWfFIV2Fn36"],"authorship_tag":"ABX9TyMtKOZAbWJjvUocidx0CUJz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NQPxblfo33Un"},"source":["# **AIDI-1010**"]},{"cell_type":"markdown","metadata":{"id":"c8xo0n4F38rv"},"source":["# **Contents:**\n","**Module: TPOT**\n","\n","1.   Installing The Module (TPOT)\n","2.   Example-A (Classification)\n","3.   Example-B (Regression)\n","4.   Takeaways & Homework\n","5.   Offline Examples\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5ANNeGFj4bLU"},"source":["# **1 - Installing TPOT (Google Colab)**"]},{"cell_type":"code","metadata":{"id":"5MgvYkpm8hZz"},"source":["#1.1 - Install Linux Dependencies & Module (1.5mins)\n","!sudo apt-get install build-essential swig\n","!pip install TPOT\n","!pip install dask==2021.6.2 dask-glm==0.2.0 dask-ml==1.0.0\n","!pip install distributed==2021.6.2\n","!pip install cloudpickle==1.5.0\n","!pip install dask distributed --upgrade\n","!pip install tornado==5.1.0\n","!pip install xgboost==1.1.0\n","!pip install pipelineprofiler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FNCjc9zJ8uF5"},"source":["**Note: Restart Runtime & Re-Run below**"]},{"cell_type":"code","metadata":{"id":"viGBR7ax85Qh"},"source":["#1.2 - Re-Check Linux Dependencies & Module\n","!sudo apt-get install build-essential swig\n","!pip install TPOT\n","!pip install dask==2021.6.2 dask-glm==0.2.0 dask-ml==1.0.0\n","!pip install distributed==2021.6.2\n","!pip install cloudpickle==1.5.0\n","!pip install dask distributed --upgrade\n","!pip install tornado==5.1.0\n","!pip install xgboost==1.1.0\n","!pip install pipelineprofiler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q51dKAzaM7KW"},"source":["# **2- ExampleA (Classification)**"]},{"cell_type":"code","metadata":{"id":"AHEHppO0M-T2"},"source":["#Scenario: Sonar dataset, binary classification. Predict whether sonar returns indicate a rock or simulated mine.\n","\n","#2.1 - Load Modules\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from tpot import TPOTClassifier\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcSShvIZNZU4"},"source":["#2.2 - Load Dataset\n","dfA = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv')\n","\n","print(\"Data types: \\n\",dfA.dtypes,\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXzIiqgXIq9K"},"source":["print(dfA.info(),\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbCGP12mIxKU"},"source":["print(\"Head records: \\n\",dfA.head(),\"\\n\")\n","print(\"Shape/Data in dataframe: \\n\",dfA)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nCiCJSqnNrWc"},"source":["#2.3.1 - Split data into input/output elements\n","datasetA = dfA.values\n","X2, y2 = datasetA[:,:-1], datasetA[:,-1]\n","\n","#2.3.2 - Minimally prepare the dataset\n","X2 = X2.astype('float32')\n","y2 = LabelEncoder().fit_transform(y2.astype('str'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipP3PZvrOUIj"},"source":["#2.4 - Define evaluation procedure\n","cvA = RepeatedStratifiedKFold(n_splits=10, n_repeats=3,random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UMwKq-sKARA"},"source":["#2.5 - Define Model\n","modelTPOTA = TPOTClassifier(generations=5,population_size=50,cv=cvA,scoring='accuracy',verbosity=2,random_state=1,n_jobs=1,max_time_mins=2)\n","\n","#2.6 - Fit data into Model\n","modelTPOTA.fit(X2, y2)\n","\n","#2.7 - Export best model\n","modelTPOTA.export('TPOT_A_sonar_best_model.py')\n","\n","#2.8 - Show the best pipeline\n","modelTPOTA.fitted_pipeline_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JOY0qqSWPHJP"},"source":["**Takeaway1:** Can you reach a higher accuracy? How?"]},{"cell_type":"markdown","metadata":{"id":"NBgC84jrPHJb"},"source":["**Takeaway2:** What's the accuracy of newer data (if you created any)? What other useful parameters were you able to find?"]},{"cell_type":"markdown","metadata":{"id":"hyN_oiUtPHJb"},"source":["**Takeaway3:** Make a prediction on a new row of data"]},{"cell_type":"markdown","metadata":{"id":"PBIpDYsPHGNk"},"source":["# **3- ExampleB (Regression)**"]},{"cell_type":"code","metadata":{"id":"T4tvMDWuIzJp"},"source":["#Scenario: Auto-Insurance data - predicting the claims again, like last in autosklearn\n","\n","#3.1 - Load Modules\n","import pandas as pd\n","from sklearn.model_selection import RepeatedKFold\n","from tpot import TPOTRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nIWjn3hRJP2k"},"source":["#3.2 - Load Dataset\n","dfB = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv')\n","\n","print(\"Data types: \\n\",dfB.dtypes,\"\\n\")\n","print(dfB.info(),\"\\n\")\n","print(\"Head Records: \\n\",dfB.head(),\"\\n\")\n","print(\"Shape/Data in dataframe: \\n\",dfB)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlHM9eG7Jtn5"},"source":["#3.3 - Split data into input/output elements\n","datasetB = dfB.values\n","datasetB = datasetB.astype('float32')\n","X3, y3 = datasetB[:,:-1], datasetB[:,-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCw_HgWaKFaS"},"source":["#3.4 - Define evaluation procedure\n","cvB = RepeatedKFold(n_splits=10,n_repeats=3,random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-y_7wZe0KNOo"},"source":["#3.5 - Define Model\n","modelTPOTB = TPOTRegressor(generations=5,population_size=50,scoring='neg_mean_absolute_error',cv=cvB, verbosity=2, random_state=1,n_jobs=1,max_time_mins=5)\n","\n","#3.6 - Fit data into Model\n","modelTPOTB.fit(X3,y3)\n","\n","#4.7 - Export best model\n","modelTPOTB.export('TPOT_B_insurance_best_model.py')\n","\n","#4.8 - Show the best pipeline\n","modelTPOTB.fitted_pipeline_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"On7Q_O2vLtXc"},"source":["**Takeaway1:** Can you reach a higher accuracy? How?"]},{"cell_type":"markdown","metadata":{"id":"-xZtlhq_LtXd"},"source":["**Takeaway2:** What's the accuracy of newer data (if you created any)? What other useful parameters were you able to find?"]},{"cell_type":"markdown","metadata":{"id":"OPcIDLCOLtXd"},"source":["**Takeaway3:** Make a prediction on a new row of data"]},{"cell_type":"markdown","metadata":{"id":"NOb_oHzaQca6"},"source":["# **4- Takeaways & Homework**"]},{"cell_type":"markdown","metadata":{"id":"kicK95izQf10"},"source":["https://epistasislab.github.io/tpot/examples/ \n","\n","\n","https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9"]},{"cell_type":"markdown","metadata":{"id":"YaMmO6202egv"},"source":["# **5A - (Classification)**"]},{"cell_type":"code","metadata":{"id":"nR6rB4Jg-DMb"},"source":["#Credit: https://towardsdatascience.com/tpot-automated-machine-learning-in-python-e56800e69c11\n","\n","#5A.1 - Loading Modules to prepare Dataset\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hrAyC6D-DFl"},"source":["#5A.2 - Import Data\n","data5A = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n","data5A.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"turhtUFV-C7b"},"source":["#5A.3 - Data preparation; Use 6 techniques below..\n","\n","#5A.3.1 - Drop irrelevant columns\n","data5A.drop(['Ticket', 'PassengerId'], axis=1, inplace=True)\n","\n","#5A.3.2 - Remap/Convert Sex column to integer representation: 0s/1s\n","gender_mapper = {'male':0, 'female':1} #males zero and females ones\n","data5A['Sex'].replace(gender_mapper,inplace=True) #use replace function\n","\n","#5A.3.3 - Check if passenger had a unique title (like doctor) or generic (Mr, Mrs) extract it from Name column\n","data5A['Title'] = data5A['Name'].apply(lambda x: x.split(',')[1].strip().split(' ')[0])\n","data5A['Title'] = [0 if x in ['Mr.', 'Miss', 'Mrs.'] else 1 for x in data5A['Title']] #set title to zero if title is common\n","data5A = data5A.rename(columns={'Title': 'Title_Unusual'}) #rename column \n","data5A.drop('Name',axis=1,inplace=True) #drop previously declared \"Name\" column  \n","\n","#5A.3.4 - Check if cabin information was known - if value is Cabin column is NOT NAN\n","data5A['Cabin_Known'] = [0 if str(x) == 'nan' else 1 for x in data5A['Cabin']]\n","data5A.drop('Cabin',axis=1,inplace=True)\n","\n","#5A.3.5 - Create dummy variables from Embarked column - \n","emb_dummies = pd.get_dummies(data5A['Embarked'],drop_first=True,prefix='Embarked') #this will result in another df object which needs to be concatenated to original column\n","data5A = pd.concat([data5A,emb_dummies],axis=1) #concatenation\n","data5A.drop('Embarked',axis=1,inplace=True)\n","\n","#5A.3.6 - Fill Age values with simple mean of the column\n","data5A['Age'] = data5A['Age'].fillna(int(data5A['Age'].mean()))\n","\n","data5A.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"preYZFkkn3xy"},"source":["Columns \"AGE\" and \"FARE\" have decimals - need to use standard scaler."]},{"cell_type":"code","metadata":{"id":"EyZ1K-oIoHI5"},"source":["#5A.3.7 - Split the Data\n","X = data5A.drop('Survived',axis=1)\n","y = data5A['Survived']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) #80% for training and rest for testing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q3lvyHmcqvKr"},"source":["#5A.3.8 - Standard Scaler to fit train data and transform train/test data\n","\n","ss = StandardScaler()\n","X_train_scaled = ss.fit_transform(X_train)\n","X_test_scaled = ss.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_96qd_XAs9Y"},"source":["#5A.4 - Loading Modules to use TPOT\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from tpot import TPOTClassifier #TPOT's Classifier\n","import pandas as pd\n","import PipelineProfiler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rruAFHhereOq"},"source":["#5A.5 - Training Process/Fit the data into model\n","tpot5A = TPOTClassifier(verbosity=2,max_time_mins=10) #10minutes is usually the norm\n","tpot5A.fit(X_train_scaled, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZ2WTUbxEccq"},"source":["**Question: What do the statistics show?**\n","- How many runs? how many successful runs? "]},{"cell_type":"code","metadata":{"id":"7klmL6JUsG9b"},"source":["#5A.6 - Show the best pipeline\n","tpot5A.fitted_pipeline_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JhKesL4PtE72"},"source":["#5A.7 - Show the accuracy on test set\n","tpot5A.score(X_test_scaled, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZXuGc9yZ6vX6"},"source":["**Takeaway1:** Can you reach a higher percentage? How? "]},{"cell_type":"markdown","metadata":{"id":"h02BSKJz9hWq"},"source":["**Takeaway2:** What's the accuracy of newer data (if you created any)? What other useful parameters were you able to find?"]},{"cell_type":"markdown","metadata":{"id":"DyWfFIV2Fn36"},"source":["# **5B - (Classification)**"]},{"cell_type":"markdown","metadata":{"id":"_GHJXVvQ-0ga"},"source":["Scenario:\n","Predict prevalence of diabetes within 5 years of using Pima Indians Diabetest Dataset. \n","\n","Maximum accuracy achieved has been 77.47% thus far."]},{"cell_type":"code","metadata":{"id":"oer9gDRn76D0"},"source":["#5B.1 - Load Modules\n","import tpot\n","from tpot import TPOTClassifier\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFxJKACG1w72"},"source":["#5B.2 - Load Data\n","df5B = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv')\n","print(\"Data Types: \\n\",df5B.dtypes,\"\\n\")\n","print(df5b.info(),\"\\n\")\n","print(\"Head Records: \\n\",df5B.head(),\"\\n\")\n","print(\"Shape/Data in dataframe: \\n\",df5B)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8Mh4JXm1-jS"},"source":["#5B.3 - Splitting Data into input/output features\n","data5B = df5B.values\n","X5B, y5B = data5B[:, :-1], data5B[:, -1]\n","print(X5B.shape, y5B.shape)\n","\n","X5B = X5B.astype('float32')\n","y5B = LabelEncoder().fit_transform(y5B.astype('str'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rot_GZlT-O9f"},"source":["#5B.4.1 - Model evaluation definition using StratifiedKfold = 10 folds\n","cv5B = StratifiedKFold(n_splits=10)\n","\n","#5B.4.2 - Define TPOTClassifier\n","modelTPOT5B = TPOTClassifier(generations=5,population_size=50,cv=cv5B,scoring='accuracy',verbosity=2,random_state=1,n_jobs=1,max_time_mins=10)\n","\n","#5B.4.3 - Fit the data into model\n","modelTPOT5B.fit(X5B,y5B)\n","\n","#5B.4.4 - Export best model\n","modelTPOT5B.export('TPOT_5B_data.py')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrUUxIuBF2lI"},"source":["#5B.4.5 - Show the best pipeline\n","modelTPOT5B.fitted_pipeline_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OzxZzYShPclF"},"source":["**Takeaway1:** Can you reach a higher accuracy? How?"]},{"cell_type":"markdown","metadata":{"id":"aJ48rzuJPclF"},"source":["**Takeaway2:** What's the accuracy of newer data (if you created any)? What other useful parameters were you able to find?"]},{"cell_type":"markdown","metadata":{"id":"BKjjU_X6HiGP"},"source":["**Takeaway3:** Try experiment with StratifiedKfold = 5 folds"]},{"cell_type":"markdown","metadata":{"id":"zo_HTpJ9IryX"},"source":["**Takeaway4:** Make a prediction on a new row of data"]}]}